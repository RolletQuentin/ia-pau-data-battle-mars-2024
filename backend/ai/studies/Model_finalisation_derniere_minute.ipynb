{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modèle 1 : Finalisation dernière minute\n",
    "\n",
    "- On ajoute des poids pour bénéficier \"Définition\" \\*1.3 et réduire \"Titre\" \\*0.7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /home/patrice/Documents/Etudes/CY-Tech/Ing2_Sem2_2023-2024/UE7_Projet_DataBattle_IA-Pau/ia-pau-data-battle-mars-2024/backend/venv/lib/python3.11/site-packages (2.2.1)\n",
      "Requirement already satisfied: spacy in /home/patrice/Documents/Etudes/CY-Tech/Ing2_Sem2_2023-2024/UE7_Projet_DataBattle_IA-Pau/ia-pau-data-battle-mars-2024/backend/venv/lib/python3.11/site-packages (3.7.4)\n",
      "Requirement already satisfied: bs4 in /home/patrice/Documents/Etudes/CY-Tech/Ing2_Sem2_2023-2024/UE7_Projet_DataBattle_IA-Pau/ia-pau-data-battle-mars-2024/backend/venv/lib/python3.11/site-packages (0.0.2)\n",
      "Requirement already satisfied: sentence_transformers in /home/patrice/Documents/Etudes/CY-Tech/Ing2_Sem2_2023-2024/UE7_Projet_DataBattle_IA-Pau/ia-pau-data-battle-mars-2024/backend/venv/lib/python3.11/site-packages (2.6.0)\n",
      "Requirement already satisfied: numpy in /home/patrice/Documents/Etudes/CY-Tech/Ing2_Sem2_2023-2024/UE7_Projet_DataBattle_IA-Pau/ia-pau-data-battle-mars-2024/backend/venv/lib/python3.11/site-packages (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/patrice/Documents/Etudes/CY-Tech/Ing2_Sem2_2023-2024/UE7_Projet_DataBattle_IA-Pau/ia-pau-data-battle-mars-2024/backend/venv/lib/python3.11/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/patrice/Documents/Etudes/CY-Tech/Ing2_Sem2_2023-2024/UE7_Projet_DataBattle_IA-Pau/ia-pau-data-battle-mars-2024/backend/venv/lib/python3.11/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/patrice/Documents/Etudes/CY-Tech/Ing2_Sem2_2023-2024/UE7_Projet_DataBattle_IA-Pau/ia-pau-data-battle-mars-2024/backend/venv/lib/python3.11/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /home/patrice/Documents/Etudes/CY-Tech/Ing2_Sem2_2023-2024/UE7_Projet_DataBattle_IA-Pau/ia-pau-data-battle-mars-2024/backend/venv/lib/python3.11/site-packages (from spacy) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /home/patrice/Documents/Etudes/CY-Tech/Ing2_Sem2_2023-2024/UE7_Projet_DataBattle_IA-Pau/ia-pau-data-battle-mars-2024/backend/venv/lib/python3.11/site-packages (from spacy) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /home/patrice/Documents/Etudes/CY-Tech/Ing2_Sem2_2023-2024/UE7_Projet_DataBattle_IA-Pau/ia-pau-data-battle-mars-2024/backend/venv/lib/python3.11/site-packages (from spacy) (1.0.10)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /home/patrice/Documents/Etudes/CY-Tech/Ing2_Sem2_2023-2024/UE7_Projet_DataBattle_IA-Pau/ia-pau-data-battle-mars-2024/backend/venv/lib/python3.11/site-packages (from spacy) (2.0.8)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /home/patrice/Documents/Etudes/CY-Tech/Ing2_Sem2_2023-2024/UE7_Projet_DataBattle_IA-Pau/ia-pau-data-battle-mars-2024/backend/venv/lib/python3.11/site-packages (from spacy) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /home/patrice/Documents/Etudes/CY-Tech/Ing2_Sem2_2023-2024/UE7_Projet_DataBattle_IA-Pau/ia-pau-data-battle-mars-2024/backend/venv/lib/python3.11/site-packages (from spacy) (8.2.3)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /home/patrice/Documents/Etudes/CY-Tech/Ing2_Sem2_2023-2024/UE7_Projet_DataBattle_IA-Pau/ia-pau-data-battle-mars-2024/backend/venv/lib/python3.11/site-packages (from spacy) (1.1.2)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /home/patrice/Documents/Etudes/CY-Tech/Ing2_Sem2_2023-2024/UE7_Projet_DataBattle_IA-Pau/ia-pau-data-battle-mars-2024/backend/venv/lib/python3.11/site-packages (from spacy) (2.4.8)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /home/patrice/Documents/Etudes/CY-Tech/Ing2_Sem2_2023-2024/UE7_Projet_DataBattle_IA-Pau/ia-pau-data-battle-mars-2024/backend/venv/lib/python3.11/site-packages (from spacy) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in /home/patrice/Documents/Etudes/CY-Tech/Ing2_Sem2_2023-2024/UE7_Projet_DataBattle_IA-Pau/ia-pau-data-battle-mars-2024/backend/venv/lib/python3.11/site-packages (from spacy) (0.3.4)\n",
      "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /home/patrice/Documents/Etudes/CY-Tech/Ing2_Sem2_2023-2024/UE7_Projet_DataBattle_IA-Pau/ia-pau-data-battle-mars-2024/backend/venv/lib/python3.11/site-packages (from spacy) (0.9.4)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /home/patrice/Documents/Etudes/CY-Tech/Ing2_Sem2_2023-2024/UE7_Projet_DataBattle_IA-Pau/ia-pau-data-battle-mars-2024/backend/venv/lib/python3.11/site-packages (from spacy) (6.4.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /home/patrice/Documents/Etudes/CY-Tech/Ing2_Sem2_2023-2024/UE7_Projet_DataBattle_IA-Pau/ia-pau-data-battle-mars-2024/backend/venv/lib/python3.11/site-packages (from spacy) (4.66.2)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /home/patrice/Documents/Etudes/CY-Tech/Ing2_Sem2_2023-2024/UE7_Projet_DataBattle_IA-Pau/ia-pau-data-battle-mars-2024/backend/venv/lib/python3.11/site-packages (from spacy) (2.31.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /home/patrice/Documents/Etudes/CY-Tech/Ing2_Sem2_2023-2024/UE7_Projet_DataBattle_IA-Pau/ia-pau-data-battle-mars-2024/backend/venv/lib/python3.11/site-packages (from spacy) (2.6.1)\n",
      "Requirement already satisfied: jinja2 in /home/patrice/Documents/Etudes/CY-Tech/Ing2_Sem2_2023-2024/UE7_Projet_DataBattle_IA-Pau/ia-pau-data-battle-mars-2024/backend/venv/lib/python3.11/site-packages (from spacy) (3.1.3)\n",
      "Requirement already satisfied: setuptools in /home/patrice/Documents/Etudes/CY-Tech/Ing2_Sem2_2023-2024/UE7_Projet_DataBattle_IA-Pau/ia-pau-data-battle-mars-2024/backend/venv/lib/python3.11/site-packages (from spacy) (65.5.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/patrice/Documents/Etudes/CY-Tech/Ing2_Sem2_2023-2024/UE7_Projet_DataBattle_IA-Pau/ia-pau-data-battle-mars-2024/backend/venv/lib/python3.11/site-packages (from spacy) (24.0)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /home/patrice/Documents/Etudes/CY-Tech/Ing2_Sem2_2023-2024/UE7_Projet_DataBattle_IA-Pau/ia-pau-data-battle-mars-2024/backend/venv/lib/python3.11/site-packages (from spacy) (3.3.0)\n",
      "Requirement already satisfied: beautifulsoup4 in /home/patrice/Documents/Etudes/CY-Tech/Ing2_Sem2_2023-2024/UE7_Projet_DataBattle_IA-Pau/ia-pau-data-battle-mars-2024/backend/venv/lib/python3.11/site-packages (from bs4) (4.12.3)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.32.0 in /home/patrice/Documents/Etudes/CY-Tech/Ing2_Sem2_2023-2024/UE7_Projet_DataBattle_IA-Pau/ia-pau-data-battle-mars-2024/backend/venv/lib/python3.11/site-packages (from sentence_transformers) (4.39.1)\n",
      "Requirement already satisfied: torch>=1.11.0 in /home/patrice/Documents/Etudes/CY-Tech/Ing2_Sem2_2023-2024/UE7_Projet_DataBattle_IA-Pau/ia-pau-data-battle-mars-2024/backend/venv/lib/python3.11/site-packages (from sentence_transformers) (2.2.1)\n",
      "Requirement already satisfied: scikit-learn in /home/patrice/Documents/Etudes/CY-Tech/Ing2_Sem2_2023-2024/UE7_Projet_DataBattle_IA-Pau/ia-pau-data-battle-mars-2024/backend/venv/lib/python3.11/site-packages (from sentence_transformers) (1.4.1.post1)\n",
      "Requirement already satisfied: scipy in /home/patrice/Documents/Etudes/CY-Tech/Ing2_Sem2_2023-2024/UE7_Projet_DataBattle_IA-Pau/ia-pau-data-battle-mars-2024/backend/venv/lib/python3.11/site-packages (from sentence_transformers) (1.12.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.15.1 in /home/patrice/Documents/Etudes/CY-Tech/Ing2_Sem2_2023-2024/UE7_Projet_DataBattle_IA-Pau/ia-pau-data-battle-mars-2024/backend/venv/lib/python3.11/site-packages (from sentence_transformers) (0.21.4)\n",
      "Requirement already satisfied: Pillow in /home/patrice/Documents/Etudes/CY-Tech/Ing2_Sem2_2023-2024/UE7_Projet_DataBattle_IA-Pau/ia-pau-data-battle-mars-2024/backend/venv/lib/python3.11/site-packages (from sentence_transformers) (10.2.0)\n",
      "Requirement already satisfied: filelock in /home/patrice/Documents/Etudes/CY-Tech/Ing2_Sem2_2023-2024/UE7_Projet_DataBattle_IA-Pau/ia-pau-data-battle-mars-2024/backend/venv/lib/python3.11/site-packages (from huggingface-hub>=0.15.1->sentence_transformers) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/patrice/Documents/Etudes/CY-Tech/Ing2_Sem2_2023-2024/UE7_Projet_DataBattle_IA-Pau/ia-pau-data-battle-mars-2024/backend/venv/lib/python3.11/site-packages (from huggingface-hub>=0.15.1->sentence_transformers) (2024.3.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/patrice/Documents/Etudes/CY-Tech/Ing2_Sem2_2023-2024/UE7_Projet_DataBattle_IA-Pau/ia-pau-data-battle-mars-2024/backend/venv/lib/python3.11/site-packages (from huggingface-hub>=0.15.1->sentence_transformers) (6.0.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/patrice/Documents/Etudes/CY-Tech/Ing2_Sem2_2023-2024/UE7_Projet_DataBattle_IA-Pau/ia-pau-data-battle-mars-2024/backend/venv/lib/python3.11/site-packages (from huggingface-hub>=0.15.1->sentence_transformers) (4.9.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /home/patrice/Documents/Etudes/CY-Tech/Ing2_Sem2_2023-2024/UE7_Projet_DataBattle_IA-Pau/ia-pau-data-battle-mars-2024/backend/venv/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.16.2 in /home/patrice/Documents/Etudes/CY-Tech/Ing2_Sem2_2023-2024/UE7_Projet_DataBattle_IA-Pau/ia-pau-data-battle-mars-2024/backend/venv/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.16.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/patrice/Documents/Etudes/CY-Tech/Ing2_Sem2_2023-2024/UE7_Projet_DataBattle_IA-Pau/ia-pau-data-battle-mars-2024/backend/venv/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/patrice/Documents/Etudes/CY-Tech/Ing2_Sem2_2023-2024/UE7_Projet_DataBattle_IA-Pau/ia-pau-data-battle-mars-2024/backend/venv/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/patrice/Documents/Etudes/CY-Tech/Ing2_Sem2_2023-2024/UE7_Projet_DataBattle_IA-Pau/ia-pau-data-battle-mars-2024/backend/venv/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/patrice/Documents/Etudes/CY-Tech/Ing2_Sem2_2023-2024/UE7_Projet_DataBattle_IA-Pau/ia-pau-data-battle-mars-2024/backend/venv/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/patrice/Documents/Etudes/CY-Tech/Ing2_Sem2_2023-2024/UE7_Projet_DataBattle_IA-Pau/ia-pau-data-battle-mars-2024/backend/venv/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2024.2.2)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /home/patrice/Documents/Etudes/CY-Tech/Ing2_Sem2_2023-2024/UE7_Projet_DataBattle_IA-Pau/ia-pau-data-battle-mars-2024/backend/venv/lib/python3.11/site-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.7.11)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /home/patrice/Documents/Etudes/CY-Tech/Ing2_Sem2_2023-2024/UE7_Projet_DataBattle_IA-Pau/ia-pau-data-battle-mars-2024/backend/venv/lib/python3.11/site-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.1.4)\n",
      "Requirement already satisfied: sympy in /home/patrice/Documents/Etudes/CY-Tech/Ing2_Sem2_2023-2024/UE7_Projet_DataBattle_IA-Pau/ia-pau-data-battle-mars-2024/backend/venv/lib/python3.11/site-packages (from torch>=1.11.0->sentence_transformers) (1.12)\n",
      "Requirement already satisfied: networkx in /home/patrice/Documents/Etudes/CY-Tech/Ing2_Sem2_2023-2024/UE7_Projet_DataBattle_IA-Pau/ia-pau-data-battle-mars-2024/backend/venv/lib/python3.11/site-packages (from torch>=1.11.0->sentence_transformers) (3.2.1)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/patrice/Documents/Etudes/CY-Tech/Ing2_Sem2_2023-2024/UE7_Projet_DataBattle_IA-Pau/ia-pau-data-battle-mars-2024/backend/venv/lib/python3.11/site-packages (from torch>=1.11.0->sentence_transformers) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/patrice/Documents/Etudes/CY-Tech/Ing2_Sem2_2023-2024/UE7_Projet_DataBattle_IA-Pau/ia-pau-data-battle-mars-2024/backend/venv/lib/python3.11/site-packages (from torch>=1.11.0->sentence_transformers) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/patrice/Documents/Etudes/CY-Tech/Ing2_Sem2_2023-2024/UE7_Projet_DataBattle_IA-Pau/ia-pau-data-battle-mars-2024/backend/venv/lib/python3.11/site-packages (from torch>=1.11.0->sentence_transformers) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /home/patrice/Documents/Etudes/CY-Tech/Ing2_Sem2_2023-2024/UE7_Projet_DataBattle_IA-Pau/ia-pau-data-battle-mars-2024/backend/venv/lib/python3.11/site-packages (from torch>=1.11.0->sentence_transformers) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/patrice/Documents/Etudes/CY-Tech/Ing2_Sem2_2023-2024/UE7_Projet_DataBattle_IA-Pau/ia-pau-data-battle-mars-2024/backend/venv/lib/python3.11/site-packages (from torch>=1.11.0->sentence_transformers) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/patrice/Documents/Etudes/CY-Tech/Ing2_Sem2_2023-2024/UE7_Projet_DataBattle_IA-Pau/ia-pau-data-battle-mars-2024/backend/venv/lib/python3.11/site-packages (from torch>=1.11.0->sentence_transformers) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/patrice/Documents/Etudes/CY-Tech/Ing2_Sem2_2023-2024/UE7_Projet_DataBattle_IA-Pau/ia-pau-data-battle-mars-2024/backend/venv/lib/python3.11/site-packages (from torch>=1.11.0->sentence_transformers) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/patrice/Documents/Etudes/CY-Tech/Ing2_Sem2_2023-2024/UE7_Projet_DataBattle_IA-Pau/ia-pau-data-battle-mars-2024/backend/venv/lib/python3.11/site-packages (from torch>=1.11.0->sentence_transformers) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/patrice/Documents/Etudes/CY-Tech/Ing2_Sem2_2023-2024/UE7_Projet_DataBattle_IA-Pau/ia-pau-data-battle-mars-2024/backend/venv/lib/python3.11/site-packages (from torch>=1.11.0->sentence_transformers) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /home/patrice/Documents/Etudes/CY-Tech/Ing2_Sem2_2023-2024/UE7_Projet_DataBattle_IA-Pau/ia-pau-data-battle-mars-2024/backend/venv/lib/python3.11/site-packages (from torch>=1.11.0->sentence_transformers) (2.19.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/patrice/Documents/Etudes/CY-Tech/Ing2_Sem2_2023-2024/UE7_Projet_DataBattle_IA-Pau/ia-pau-data-battle-mars-2024/backend/venv/lib/python3.11/site-packages (from torch>=1.11.0->sentence_transformers) (12.1.105)\n",
      "Requirement already satisfied: triton==2.2.0 in /home/patrice/Documents/Etudes/CY-Tech/Ing2_Sem2_2023-2024/UE7_Projet_DataBattle_IA-Pau/ia-pau-data-battle-mars-2024/backend/venv/lib/python3.11/site-packages (from torch>=1.11.0->sentence_transformers) (2.2.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/patrice/Documents/Etudes/CY-Tech/Ing2_Sem2_2023-2024/UE7_Projet_DataBattle_IA-Pau/ia-pau-data-battle-mars-2024/backend/venv/lib/python3.11/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.11.0->sentence_transformers) (12.4.99)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/patrice/Documents/Etudes/CY-Tech/Ing2_Sem2_2023-2024/UE7_Projet_DataBattle_IA-Pau/ia-pau-data-battle-mars-2024/backend/venv/lib/python3.11/site-packages (from transformers<5.0.0,>=4.32.0->sentence_transformers) (2023.12.25)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /home/patrice/Documents/Etudes/CY-Tech/Ing2_Sem2_2023-2024/UE7_Projet_DataBattle_IA-Pau/ia-pau-data-battle-mars-2024/backend/venv/lib/python3.11/site-packages (from transformers<5.0.0,>=4.32.0->sentence_transformers) (0.15.2)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /home/patrice/Documents/Etudes/CY-Tech/Ing2_Sem2_2023-2024/UE7_Projet_DataBattle_IA-Pau/ia-pau-data-battle-mars-2024/backend/venv/lib/python3.11/site-packages (from transformers<5.0.0,>=4.32.0->sentence_transformers) (0.4.2)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /home/patrice/Documents/Etudes/CY-Tech/Ing2_Sem2_2023-2024/UE7_Projet_DataBattle_IA-Pau/ia-pau-data-battle-mars-2024/backend/venv/lib/python3.11/site-packages (from typer<0.10.0,>=0.3.0->spacy) (8.1.7)\n",
      "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /home/patrice/Documents/Etudes/CY-Tech/Ing2_Sem2_2023-2024/UE7_Projet_DataBattle_IA-Pau/ia-pau-data-battle-mars-2024/backend/venv/lib/python3.11/site-packages (from weasel<0.4.0,>=0.1.0->spacy) (0.16.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in /home/patrice/Documents/Etudes/CY-Tech/Ing2_Sem2_2023-2024/UE7_Projet_DataBattle_IA-Pau/ia-pau-data-battle-mars-2024/backend/venv/lib/python3.11/site-packages (from beautifulsoup4->bs4) (2.5)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/patrice/Documents/Etudes/CY-Tech/Ing2_Sem2_2023-2024/UE7_Projet_DataBattle_IA-Pau/ia-pau-data-battle-mars-2024/backend/venv/lib/python3.11/site-packages (from jinja2->spacy) (2.1.5)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /home/patrice/Documents/Etudes/CY-Tech/Ing2_Sem2_2023-2024/UE7_Projet_DataBattle_IA-Pau/ia-pau-data-battle-mars-2024/backend/venv/lib/python3.11/site-packages (from scikit-learn->sentence_transformers) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/patrice/Documents/Etudes/CY-Tech/Ing2_Sem2_2023-2024/UE7_Projet_DataBattle_IA-Pau/ia-pau-data-battle-mars-2024/backend/venv/lib/python3.11/site-packages (from scikit-learn->sentence_transformers) (3.4.0)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/patrice/Documents/Etudes/CY-Tech/Ing2_Sem2_2023-2024/UE7_Projet_DataBattle_IA-Pau/ia-pau-data-battle-mars-2024/backend/venv/lib/python3.11/site-packages (from sympy->torch>=1.11.0->sentence_transformers) (1.3.0)\n",
      "Collecting fr-core-news-sm==3.7.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/fr_core_news_sm-3.7.0/fr_core_news_sm-3.7.0-py3-none-any.whl (16.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.3/16.3 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.0 in /home/patrice/Documents/Etudes/CY-Tech/Ing2_Sem2_2023-2024/UE7_Projet_DataBattle_IA-Pau/ia-pau-data-battle-mars-2024/backend/venv/lib/python3.11/site-packages (from fr-core-news-sm==3.7.0) (3.7.4)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /home/patrice/Documents/Etudes/CY-Tech/Ing2_Sem2_2023-2024/UE7_Projet_DataBattle_IA-Pau/ia-pau-data-battle-mars-2024/backend/venv/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /home/patrice/Documents/Etudes/CY-Tech/Ing2_Sem2_2023-2024/UE7_Projet_DataBattle_IA-Pau/ia-pau-data-battle-mars-2024/backend/venv/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /home/patrice/Documents/Etudes/CY-Tech/Ing2_Sem2_2023-2024/UE7_Projet_DataBattle_IA-Pau/ia-pau-data-battle-mars-2024/backend/venv/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (1.0.10)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /home/patrice/Documents/Etudes/CY-Tech/Ing2_Sem2_2023-2024/UE7_Projet_DataBattle_IA-Pau/ia-pau-data-battle-mars-2024/backend/venv/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (2.0.8)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /home/patrice/Documents/Etudes/CY-Tech/Ing2_Sem2_2023-2024/UE7_Projet_DataBattle_IA-Pau/ia-pau-data-battle-mars-2024/backend/venv/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /home/patrice/Documents/Etudes/CY-Tech/Ing2_Sem2_2023-2024/UE7_Projet_DataBattle_IA-Pau/ia-pau-data-battle-mars-2024/backend/venv/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (8.2.3)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /home/patrice/Documents/Etudes/CY-Tech/Ing2_Sem2_2023-2024/UE7_Projet_DataBattle_IA-Pau/ia-pau-data-battle-mars-2024/backend/venv/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (1.1.2)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /home/patrice/Documents/Etudes/CY-Tech/Ing2_Sem2_2023-2024/UE7_Projet_DataBattle_IA-Pau/ia-pau-data-battle-mars-2024/backend/venv/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (2.4.8)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /home/patrice/Documents/Etudes/CY-Tech/Ing2_Sem2_2023-2024/UE7_Projet_DataBattle_IA-Pau/ia-pau-data-battle-mars-2024/backend/venv/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in /home/patrice/Documents/Etudes/CY-Tech/Ing2_Sem2_2023-2024/UE7_Projet_DataBattle_IA-Pau/ia-pau-data-battle-mars-2024/backend/venv/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (0.3.4)\n",
      "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /home/patrice/Documents/Etudes/CY-Tech/Ing2_Sem2_2023-2024/UE7_Projet_DataBattle_IA-Pau/ia-pau-data-battle-mars-2024/backend/venv/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (0.9.4)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /home/patrice/Documents/Etudes/CY-Tech/Ing2_Sem2_2023-2024/UE7_Projet_DataBattle_IA-Pau/ia-pau-data-battle-mars-2024/backend/venv/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (6.4.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /home/patrice/Documents/Etudes/CY-Tech/Ing2_Sem2_2023-2024/UE7_Projet_DataBattle_IA-Pau/ia-pau-data-battle-mars-2024/backend/venv/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (4.66.2)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /home/patrice/Documents/Etudes/CY-Tech/Ing2_Sem2_2023-2024/UE7_Projet_DataBattle_IA-Pau/ia-pau-data-battle-mars-2024/backend/venv/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (2.31.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /home/patrice/Documents/Etudes/CY-Tech/Ing2_Sem2_2023-2024/UE7_Projet_DataBattle_IA-Pau/ia-pau-data-battle-mars-2024/backend/venv/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (2.6.1)\n",
      "Requirement already satisfied: jinja2 in /home/patrice/Documents/Etudes/CY-Tech/Ing2_Sem2_2023-2024/UE7_Projet_DataBattle_IA-Pau/ia-pau-data-battle-mars-2024/backend/venv/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (3.1.3)\n",
      "Requirement already satisfied: setuptools in /home/patrice/Documents/Etudes/CY-Tech/Ing2_Sem2_2023-2024/UE7_Projet_DataBattle_IA-Pau/ia-pau-data-battle-mars-2024/backend/venv/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (65.5.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/patrice/Documents/Etudes/CY-Tech/Ing2_Sem2_2023-2024/UE7_Projet_DataBattle_IA-Pau/ia-pau-data-battle-mars-2024/backend/venv/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (24.0)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /home/patrice/Documents/Etudes/CY-Tech/Ing2_Sem2_2023-2024/UE7_Projet_DataBattle_IA-Pau/ia-pau-data-battle-mars-2024/backend/venv/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (3.3.0)\n",
      "Requirement already satisfied: numpy>=1.19.0 in /home/patrice/Documents/Etudes/CY-Tech/Ing2_Sem2_2023-2024/UE7_Projet_DataBattle_IA-Pau/ia-pau-data-battle-mars-2024/backend/venv/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (1.26.4)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /home/patrice/Documents/Etudes/CY-Tech/Ing2_Sem2_2023-2024/UE7_Projet_DataBattle_IA-Pau/ia-pau-data-battle-mars-2024/backend/venv/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.16.2 in /home/patrice/Documents/Etudes/CY-Tech/Ing2_Sem2_2023-2024/UE7_Projet_DataBattle_IA-Pau/ia-pau-data-battle-mars-2024/backend/venv/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (2.16.2)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /home/patrice/Documents/Etudes/CY-Tech/Ing2_Sem2_2023-2024/UE7_Projet_DataBattle_IA-Pau/ia-pau-data-battle-mars-2024/backend/venv/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (4.9.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/patrice/Documents/Etudes/CY-Tech/Ing2_Sem2_2023-2024/UE7_Projet_DataBattle_IA-Pau/ia-pau-data-battle-mars-2024/backend/venv/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/patrice/Documents/Etudes/CY-Tech/Ing2_Sem2_2023-2024/UE7_Projet_DataBattle_IA-Pau/ia-pau-data-battle-mars-2024/backend/venv/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/patrice/Documents/Etudes/CY-Tech/Ing2_Sem2_2023-2024/UE7_Projet_DataBattle_IA-Pau/ia-pau-data-battle-mars-2024/backend/venv/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/patrice/Documents/Etudes/CY-Tech/Ing2_Sem2_2023-2024/UE7_Projet_DataBattle_IA-Pau/ia-pau-data-battle-mars-2024/backend/venv/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (2024.2.2)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /home/patrice/Documents/Etudes/CY-Tech/Ing2_Sem2_2023-2024/UE7_Projet_DataBattle_IA-Pau/ia-pau-data-battle-mars-2024/backend/venv/lib/python3.11/site-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (0.7.11)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /home/patrice/Documents/Etudes/CY-Tech/Ing2_Sem2_2023-2024/UE7_Projet_DataBattle_IA-Pau/ia-pau-data-battle-mars-2024/backend/venv/lib/python3.11/site-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (0.1.4)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /home/patrice/Documents/Etudes/CY-Tech/Ing2_Sem2_2023-2024/UE7_Projet_DataBattle_IA-Pau/ia-pau-data-battle-mars-2024/backend/venv/lib/python3.11/site-packages (from typer<0.10.0,>=0.3.0->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (8.1.7)\n",
      "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /home/patrice/Documents/Etudes/CY-Tech/Ing2_Sem2_2023-2024/UE7_Projet_DataBattle_IA-Pau/ia-pau-data-battle-mars-2024/backend/venv/lib/python3.11/site-packages (from weasel<0.4.0,>=0.1.0->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (0.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/patrice/Documents/Etudes/CY-Tech/Ing2_Sem2_2023-2024/UE7_Projet_DataBattle_IA-Pau/ia-pau-data-battle-mars-2024/backend/venv/lib/python3.11/site-packages (from jinja2->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (2.1.5)\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('fr_core_news_sm')\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas spacy bs4 sentence_transformers numpy\n",
    "!python -m spacy download fr_core_news_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/patrice/Documents/Etudes/CY-Tech/Ing2_Sem2_2023-2024/UE7_Projet_DataBattle_IA-Pau/ia-pau-data-battle-mars-2024/backend/venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import unicodedata\n",
    "import spacy\n",
    "from bs4 import BeautifulSoup\n",
    "from spacy.lang.fr.stop_words import STOP_WORDS\n",
    "import pickle\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from sentence_transformers.quantization import quantize_embeddings\n",
    "import numpy as np\n",
    "import copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nouvelles fonctions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### On traite les données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_merge_data(csv_file='../data/solutions2.csv'):\n",
    "    dictionnaire_solution = {1: \"Titre\", 2: \"Description\", 5: \"Application\", 6: \"Bilan énergétique\", 21: \"Titre technologie\", 22: \"Description technologie\"}\n",
    "\n",
    "    # Charger le fichier CSV en spécifiant le séparateur '|'\n",
    "    df = pd.read_csv(csv_file, sep='|', header=None)\n",
    "\n",
    "    # Initialiser une liste pour stocker les données de chaque solution\n",
    "    solutions_data = []\n",
    "\n",
    "    # Parcourir chaque ligne du DataFrame\n",
    "    for index, row in df.iterrows():\n",
    "        id_sol = row[0]\n",
    "        section = row[1]\n",
    "        texte = row[2]\n",
    "\n",
    "        # Vérifier si la section correspond à une clé dans le dictionnaire de solutions\n",
    "        if section in dictionnaire_solution:\n",
    "            # Récupérer le nom de la section\n",
    "            section_name = dictionnaire_solution[section]\n",
    "\n",
    "            # Chercher si la solution existe déjà dans la liste\n",
    "            solution_exists = False\n",
    "            for solution in solutions_data:\n",
    "                if solution[0] == id_sol:\n",
    "                    solution_exists = True\n",
    "                    solution[1][section_name] = texte\n",
    "                    break\n",
    "\n",
    "            # Si la solution n'existe pas encore, la créer\n",
    "            if not solution_exists:\n",
    "                new_solution = [id_sol, {section_name: texte}]\n",
    "                solutions_data.append(new_solution)\n",
    "\n",
    "    return solutions_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, {'Titre technologie': 'Centrale froid', 'Titre': 'Installation frigorifique négative de type cascade utilisant du CO2', 'Description': 'Mise en place dune installation frigorifique négative de type cascade utilisant du CO2 comme fluide frigorigène.', 'Application': 'Pour être éligible à CEE, la mise en place doit être effectuée par un professionnel et appliquée dans des locaux de commerce de distribution alimentaire de surface de vente inférieure à 5000 m². Comparé aux autres fluides frigorigènes, le CO2 est un fluide'}]\n"
     ]
    }
   ],
   "source": [
    "# Appel de la fonction pour obtenir les données\n",
    "df_solutions = load_and_merge_data()\n",
    "print(df_solutions[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charger le modèle de langue SpaCy\n",
    "nlp = spacy.load(\"fr_core_news_sm\")\n",
    "\n",
    "def clean_df_solutions(df_solutions):\n",
    "    cleaned_data = []\n",
    "    for item in df_solutions:\n",
    "        index = item[0]\n",
    "        solution = item[1]\n",
    "        cleaned_solution = {}\n",
    "\n",
    "        for key, value in solution.items():\n",
    "            if (key == 'Titre' or key == 'Titre technologie') :\n",
    "                # Pour les titres, ne pas enlever les chiffres\n",
    "                cleaned_solution[key] = clean_text(str(value), remove_numbers=False)\n",
    "            else:\n",
    "                # Pour les autres champs, enlever les chiffres\n",
    "                cleaned_solution[key] = clean_text(str(value), remove_numbers=True)\n",
    "\n",
    "        cleaned_data.append([index, cleaned_solution])\n",
    "\n",
    "    return cleaned_data\n",
    "\n",
    "def clean_text(text, remove_numbers=True):\n",
    "    # Nettoyer HTML Tags\n",
    "    text = BeautifulSoup(text, 'html.parser').get_text()\n",
    "\n",
    "    # Remplacer \"&nbsp;.\" par rien\n",
    "    text = re.sub(r'&nbsp;\\.', '', text)\n",
    "\n",
    "    # Supprimer les \"l'\"\n",
    "    text = re.sub(r\"\\bl'\", '', text)\n",
    "\n",
    "    # Accents\n",
    "    text = unicodedata.normalize('NFD', text).encode('ascii', 'ignore').decode(\"utf-8\")\n",
    "\n",
    "    if remove_numbers:\n",
    "        # Retirer les numéros\n",
    "        text = re.sub(r'\\b\\d+\\b', '', text)\n",
    "\n",
    "    # Supprimer les caractères seuls\n",
    "    text = re.sub(r'\\b\\w\\b', '', text)\n",
    "\n",
    "    # Tokenization, Lemmatization, Removing Stopwords, Lowercase\n",
    "    doc = nlp(text)\n",
    "    cleaned_sentences = []\n",
    "    for sentence in doc.sents:\n",
    "        tokens = [token.lemma_.lower() for token in sentence if not token.is_stop and not token.is_punct and not token.is_space]\n",
    "        clean_sentence = ' '.join(tokens)\n",
    "        if clean_sentence:\n",
    "            cleaned_sentences.append(clean_sentence)  # Ajouter un point à la fin de la phrase propre\n",
    "\n",
    "    # Joining the cleaned sentences back into a single string\n",
    "    cleaned_text = ' '.join(cleaned_sentences)\n",
    "\n",
    "    return cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_28664/1373267169.py:25: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  text = BeautifulSoup(text, 'html.parser').get_text()\n"
     ]
    }
   ],
   "source": [
    "df_solutions_clean = clean_df_solutions(df_solutions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6, {'Titre technologie': 'condenseur', 'Titre': 'condenseur frigorifique haute efficacite', 'Description': 'mise place condenseur haute efficacite installation frigorifique neuf existant certification eurovent exemple garer qualite condenseur', 'Application': 'condenseur evaporatif efficace utiliser chaleur latent evacuer chaleur plupart systeme refrigerant utiliser condenseur refroidi lair levacuation chaleur condenseur evaporation utiliser filtre humidifie refroidir lair ambier entree condenseur accroître capacite devacuation chaleur', 'Bilan énergétique': 'condenseur haute efficacite energetiqu echangeur presenter faible ecart temperature lecart temperature fluide frigorigene pression condensation medium refroidissement eau air entree condenseur abaisser dabaisser consommation groupe frigorifique efficacite production frigorifique cop coefficient performance dun machine correspondre rapport quantite chaleur recupere condenseur quantite denergie electriqu total absorbee linstallation grand partie compresseur equipement supplementaire ventilateur pompe circulation deau .des donnee constructeur montrer valeur cop superieure moyenne machine utiliser condenseur classique'}]\n"
     ]
    }
   ],
   "source": [
    "print(df_solutions_clean[4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour vérifier qu'on garde les numéros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_solution_by_id(df_solutions_clean, solution_id):\n",
    "#     for item in df_solutions_clean:\n",
    "#         if item[0] == solution_id:\n",
    "#             return item[1]\n",
    "#     return None\n",
    "\n",
    "# # Utilisation de la fonction pour obtenir le dictionnaire de l'ID 22\n",
    "# solution_id_choisi = 1692\n",
    "# solution_choisie = get_solution_by_id(df_solutions_clean, solution_id_choisi)\n",
    "\n",
    "# # Afficher le dictionnaire de la solution choisie\n",
    "# print(solution_choisie)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### On charge le modèle "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No sentence-transformers model found with name dangvantuan/sentence-camembert-large. Creating a new one with MEAN pooling.\n"
     ]
    }
   ],
   "source": [
    "# Charger le modèle\n",
    "model = SentenceTransformer(\"dangvantuan/sentence-camembert-large\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sauvegarde des embeddings\n",
    "\n",
    "On va sauvegarder les embeddings en gardant le nom des champs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder_embeddings(data, model, output_file):\n",
    "    # Faire une copie de data\n",
    "    data = copy.deepcopy(data)\n",
    "    \n",
    "\n",
    "    # Fonction pour encoder chaque texte\n",
    "    def encoder_texte(texte):\n",
    "        return model.encode(texte)\n",
    "    \n",
    "\n",
    "    # Pour chaque entrée dans les données, encoder tous les champs texte\n",
    "    for entry in data:\n",
    "        # print(\"DEBUG : entry = \", entry)\n",
    "        for champ, valeur in entry[1].items():\n",
    "            # print(\"DEBUG : champ =\", champ, \", valeur = \", valeur)\n",
    "            if isinstance(valeur, str):  # S'assurer que la valeur est une chaîne de caractères\n",
    "                # Calculer l'embedding\n",
    "                embedding = encoder_texte(valeur)\n",
    "                # Remplacer le texte par l'embedding\n",
    "                entry[1][champ] = embedding.tolist()\n",
    "    # Sauvegarder les embeddings dans un fichier\n",
    "    with open(output_file, 'wb') as file:\n",
    "        pickle.dump(data, file)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_average_embedding(text, model):\n",
    "    # Diviser le texte en phrases\n",
    "    sentences = [sentence.strip() for sentence in text.split('.') if sentence.strip()]\n",
    "    sentence_embeddings = model.encode(sentences)\n",
    "    # Prendre la moyenne des embeddings des phrases\n",
    "    if len(sentence_embeddings) > 0:\n",
    "        average_embedding = np.mean(sentence_embeddings, axis=0)\n",
    "    else:\n",
    "        average_embedding = np.zeros(model.get_sentence_embedding_dimension())\n",
    "    return average_embedding\n",
    "\n",
    "def encoder_embeddings_moyenne_sentences(data, model, output_file):\n",
    "    # Faire une copie de data\n",
    "    data = copy.deepcopy(data)\n",
    "    # Pour chaque entrée dans les données, encoder tous les champs texte\n",
    "    for entry in data:\n",
    "        # print(\"DEBUG : entry = \", entry)\n",
    "        for champ, valeur in entry[1].items():\n",
    "            # print(\"DEBUG : champ =\", champ, \", valeur = \", valeur)\n",
    "            if isinstance(valeur, str):  # S'assurer que la valeur est une chaîne de caractères\n",
    "                # Calculer l'embedding en faisant la moyenne de l'embedding de chaque phrase.\n",
    "                embedding = calculate_average_embedding(valeur, model)\n",
    "                # Remplacer le texte par l'embedding\n",
    "                entry[1][champ] = embedding.tolist()\n",
    "    # Sauvegarder les embeddings dans un fichier\n",
    "    with open(output_file, 'wb') as file:\n",
    "        pickle.dump(data, file)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Commençons par calculer un embedding sur deux solutions :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_embedding_file = \"embeddings/FR_camembert_large_avec_moyenne_phrases.pkl\"\n",
    "solutions_embeddings = encoder_embeddings_moyenne_sentences(df_solutions_clean, model, path_embedding_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path_embedding_file = \"embeddings/model_final_moyenne_sentences_magb.pkl\"\n",
    "# solutions_embeddings = encoder_embeddings_moyenne_sentences(df_solutions_clean, model, path_embedding_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Pour voir notre embedding sur notre première solution.\n",
    "# for champ, valeur in solutions_embeddings[0][1].items():\n",
    "#     print(champ,\" : \", valeur)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(solutions_embeddings[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inférence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction appelé par notre utilisateur\n",
    "def model_find_solution(description, secteur, model, embeddings_file_path, seuil_similarite, min_sol, weights) :\n",
    "    # !!!!!!!!!!!! ICI ON A CHOISI DE NE PAS INCLURE LE SECTEUR DANS NOTRE MODELE, COMMENTER LA LIGNE CI-DESOSUS POUR CHANGER CELA --------------\n",
    "    secteur = \"\"\n",
    "    # -------------------------\n",
    "\n",
    "    # On commence par concaténer notre secteur et notre description.\n",
    "    requete = secteur + \". \" + description\n",
    "\n",
    "    # Ensuite on applique notre pré-processing\n",
    "    clean_requete = clean_text(requete, remove_numbers=False)\n",
    "    clean_requete_vecteur =  model.encode(clean_requete)\n",
    "\n",
    "    # On va lire notre fichier d'embeddings \n",
    "    with open(embeddings_file_path, \"rb\") as fIn:\n",
    "        solutions_embeddings = pickle.load(fIn)\n",
    "\n",
    "\n",
    "    solutions_similarities = []\n",
    "    # Maintenant pour chaque solution on va garder notre meilleur similarité cosinus avec notre requete. De plus nous ajouton un poids à chaque champs de notre solution,\n",
    "    # Description * 1.3, Titre * 0.7, et 1 pour tous les autres.\n",
    "    # On se retrouve donc avec une liste [[id_sol, max_similarité], ...]\n",
    "\n",
    "    # Pour chaque entrée dans les données, encoder tous les champs texte\n",
    "    for entry in solutions_embeddings:\n",
    "        max_similarity = 0\n",
    "        id_solution = entry[0]\n",
    "        for champ, valeur_vecteur in entry[1].items():\n",
    "            # Coeficient multiplicateur \n",
    "            weight = weights[champ]\n",
    "            # On calcul la similarité\n",
    "            similarity = util.pytorch_cos_sim(valeur_vecteur, clean_requete_vecteur)*weight\n",
    "            # On met à jour le max de similarité\n",
    "            if similarity > max_similarity :\n",
    "                max_similarity = similarity\n",
    "        solution_similarity = [id_solution, max_similarity]\n",
    "        solutions_similarities.append(solution_similarity)\n",
    "    #print(\"DEBUG : \",solutions_similarities)\n",
    "    \n",
    "    \n",
    "    # On trie notre liste de solution par ordre croissant\n",
    "    solutions_similarities.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # On sélectionne les 5 meilleures solutions\n",
    "    top_5_solutions = [sol[0] for sol in solutions_similarities[:min_sol]]\n",
    "\n",
    "    # On applique le seuil de similarité aux solutions restantes\n",
    "    remaining_solutions = [sol[0] for sol in solutions_similarities[min_sol:] if sol[1] > seuil_similarite]\n",
    "\n",
    "    # On concatène les deux listes de solutions\n",
    "    final_solutions = top_5_solutions + remaining_solutions\n",
    "\n",
    "    # On retourne que les solutions et non la similarité\n",
    "    return final_solutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = {\"Titre\":1, \"Description\":1, \"Application\":1, \"Bilan énergétique\":1, \"Titre technologie\":1, \"Description technologie\":1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path_embedding_file = \"embeddings/model_final_magb_avant_ajout_points.pkl\"\n",
    "# model_find_solution(\"C'est quoi la HP flottante ?\", \"\", model, path_embedding_file, 0.7, 5, weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path_embedding_file = \"embeddings/model_final_magb.pkl\"\n",
    "# model_find_solution(\"C'est quoi la HP flottante ?\", \"\", model, path_embedding_file, 0.7, 5, weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path_embedding_file = \"embeddings/model_final_moyenne_sentences_magb.pkl\"\n",
    "# model_find_solution(\"C'est quoi la HP flottante ?\", \"\", model, path_embedding_file, 0.7, 5, weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[724, 835, 1533, 1608, 1595]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_embedding_file = \"embeddings/model_final_magb_sans_somme_sentences.pkl\"\n",
    "model_find_solution(\"C'est quoi la HP flottante ?\", \"\", model, path_embedding_file, 0.7, 5, weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[724, 1604, 1602, 1603, 1605]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_embedding_file = \"embeddings/FR_camembert_large_avec_moyenne_phrases.pkl\"\n",
    "model_find_solution(\"C'est quoi la HP flottante ?\", \"\", model, path_embedding_file, 0.7, 5, weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tester sur dataset Kerdos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lire le fichier CSV\n",
    "df_testset = pd.read_csv(\"data/dataset_test_Kerdos.csv\")\n",
    "#df_testset = pd.read_csv(\"data/patrice_test_set.csv\")\n",
    "\n",
    "\n",
    "def test_accuracy(path_embedding_file, dataset=df_testset, top_n=1) :\n",
    "    accuracy = 0\n",
    "    for i in range(1,len(dataset)):\n",
    "        predictions = model_find_solution(dataset['Description'][i], \"\", model, path_embedding_file, 0.8, 5, weights)\n",
    "        # print(\"---------------------------------------\")\n",
    "        # print(\"Valeur attendu : \", dataset[\"id_solution\"][i])\n",
    "        # print(predictions)\n",
    "        if (dataset[\"id_solution\"][i] in predictions[:top_n]):\n",
    "            accuracy += 1/len(dataset)\n",
    "        # else :\n",
    "        #     print(\"mal prédit : \", dataset[\"id_solution\"][i])\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path_embedding_file = \"embeddings/model_final_magb_avant_ajout_points.pkl\"\n",
    "# test_accuracy(path_embedding_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path_embedding_file = \"embeddings/model_final_magb.pkl\"\n",
    "# test_accuracy(path_embedding_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path_embedding_file = \"embeddings/model_final_moyenne_sentences_magb.pkl\"\n",
    "# test_accuracy(path_embedding_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.25"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_embedding_file = \"embeddings/model_final_magb_sans_somme_sentences.pkl\"\n",
    "test_accuracy(path_embedding_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1875"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_embedding_file = \"embeddings/FR_camembert_large_avec_moyenne_phrases.pkl\"\n",
    "test_accuracy(path_embedding_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FONCTIONS POUR OPTIMISER ACCURACY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Répétition des fonctions à run exclusivement pour ces tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset et weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lire le fichier CSV\n",
    "df_testset = pd.read_csv(\"data/dataset_test_Kerdos.csv\")\n",
    "#df_testset = pd.read_csv(\"data/patrice_test_set.csv\")\n",
    "\n",
    "weights = {\"Titre\":1, \"Description\":1, \"Application\":1, \"Bilan énergétique\":1, \"Titre technologie\":1, \"Description technologie\":1}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algo d'optimisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Importations nécessaires\n",
    "# import itertools\n",
    "\n",
    "# # Définition des poids à tester\n",
    "# weights_to_try = {\n",
    "#     \"Titre\": [0.5, 1],\n",
    "#     \"Description\": [0.5, 1],\n",
    "#     \"Application\": [0.5, 1],\n",
    "#     \"Bilan énergétique\": [0.5, 1],\n",
    "#     \"Titre technologie\": [0.5, 1],\n",
    "#     \"Description technologie\": [0.5, 1],\n",
    "# }\n",
    "\n",
    "# best_accuracy = 0.0\n",
    "# best_weights = None\n",
    "\n",
    "# # Parcourir toutes les combinaisons de poids\n",
    "# for weights_combination in itertools.product(*weights_to_try.values()):\n",
    "#     # Créer un dictionnaire de poids à partir de la combinaison\n",
    "#     weights = dict(zip(weights_to_try.keys(), weights_combination))\n",
    "    \n",
    "#     # Calculer l'accuracy pour cette combinaison de poids\n",
    "#     accuracy = test_accuracy(path_embedding_file, df_testset, top_n=3)\n",
    "    \n",
    "#     # Vérifier si c'est la meilleure accuracy jusqu'à présent\n",
    "#     if accuracy > best_accuracy:\n",
    "#         best_accuracy = accuracy\n",
    "#         print(\"Best accuracy : \", best_accuracy)\n",
    "#         best_weights = weights.copy()\n",
    "#         print(\"Best weight : \", best_weights)\n",
    "\n",
    "# print(\"Meilleure accuracy trouvée:\", best_accuracy)\n",
    "# print(\"Meilleurs poids associés:\")\n",
    "# print(best_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best accuracy :  0.375\n",
      "Best weight :  {'Titre': 2, 'Description': 2, 'Application': 2, 'Bilan énergétique': 2, 'Titre technologie': 1.5, 'Description technologie': 0.7}\n",
      "Best accuracy :  0.625\n",
      "Best weight :  {'Titre': 2, 'Description': 2, 'Application': 2, 'Bilan énergétique': 2, 'Titre technologie': 1.5, 'Description technologie': 0.7}\n",
      "Best accuracy :  0.6875\n",
      "Best weight :  {'Titre': 2, 'Description': 1.9, 'Application': 1.9, 'Bilan énergétique': 1.7, 'Titre technologie': 0.7, 'Description technologie': 1.5}\n",
      "Best accuracy :  0.5\n",
      "Best weight :  {'Titre': 1.7, 'Description': 2, 'Application': 0.7, 'Bilan énergétique': 1.7, 'Titre technologie': 0.7, 'Description technologie': 2}\n",
      "Best accuracy :  0.75\n",
      "Best weight :  {'Titre': 1.7, 'Description': 2, 'Application': 1.5, 'Bilan énergétique': 0.5, 'Titre technologie': 1.9, 'Description technologie': 1.5}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[47], line 33\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m# Calculer l'accuracy pour cette combinaison de poids\u001b[39;00m\n\u001b[1;32m     32\u001b[0m accuracy_top_1 \u001b[38;5;241m=\u001b[39m test_accuracy(path_embedding_file, df_testset, top_n\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 33\u001b[0m accuracy_top_3 \u001b[38;5;241m=\u001b[39m \u001b[43mtest_accuracy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath_embedding_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf_testset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_n\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;66;03m# Vérifier si c'est la meilleure accuracy jusqu'à présent\u001b[39;00m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m accuracy_top_1 \u001b[38;5;241m>\u001b[39m best_accuracy_top_1:\n",
      "Cell \u001b[0;32mIn[23], line 9\u001b[0m, in \u001b[0;36mtest_accuracy\u001b[0;34m(path_embedding_file, dataset, top_n)\u001b[0m\n\u001b[1;32m      7\u001b[0m accuracy \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;28mlen\u001b[39m(dataset)):\n\u001b[0;32m----> 9\u001b[0m     predictions \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_find_solution\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mDescription\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath_embedding_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.8\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweights\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;66;03m# print(\"---------------------------------------\")\u001b[39;00m\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;66;03m# print(\"Valeur attendu : \", dataset[\"id_solution\"][i])\u001b[39;00m\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;66;03m# print(predictions)\u001b[39;00m\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (dataset[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid_solution\u001b[39m\u001b[38;5;124m\"\u001b[39m][i] \u001b[38;5;129;01min\u001b[39;00m predictions[:top_n]):\n",
      "Cell \u001b[0;32mIn[17], line 32\u001b[0m, in \u001b[0;36mmodel_find_solution\u001b[0;34m(description, secteur, model, embeddings_file_path, seuil_similarite, min_sol, weights)\u001b[0m\n\u001b[1;32m     30\u001b[0m weight \u001b[38;5;241m=\u001b[39m weights[champ]\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m# On calcul la similarité\u001b[39;00m\n\u001b[0;32m---> 32\u001b[0m similarity \u001b[38;5;241m=\u001b[39m \u001b[43mutil\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpytorch_cos_sim\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvaleur_vecteur\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclean_requete_vecteur\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m*\u001b[39mweight\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m# On met à jour le max de similarité\u001b[39;00m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m similarity \u001b[38;5;241m>\u001b[39m max_similarity :\n",
      "File \u001b[0;32m~/Documents/Etudes/CY-Tech/Ing2_Sem2_2023-2024/UE7_Projet_DataBattle_IA-Pau/ia-pau-data-battle-mars-2024/backend/venv/lib/python3.11/site-packages/sentence_transformers/util.py:28\u001b[0m, in \u001b[0;36mpytorch_cos_sim\u001b[0;34m(a, b)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpytorch_cos_sim\u001b[39m(a: Tensor, b: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m     23\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;124;03m    Computes the cosine similarity cos_sim(a[i], b[j]) for all i and j.\u001b[39;00m\n\u001b[1;32m     25\u001b[0m \n\u001b[1;32m     26\u001b[0m \u001b[38;5;124;03m    :return: Matrix with res[i][j]  = cos_sim(a[i], b[j])\u001b[39;00m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 28\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcos_sim\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Etudes/CY-Tech/Ing2_Sem2_2023-2024/UE7_Projet_DataBattle_IA-Pau/ia-pau-data-battle-mars-2024/backend/venv/lib/python3.11/site-packages/sentence_transformers/util.py:38\u001b[0m, in \u001b[0;36mcos_sim\u001b[0;34m(a, b)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;124;03mComputes the cosine similarity cos_sim(a[i], b[j]) for all i and j.\u001b[39;00m\n\u001b[1;32m     34\u001b[0m \n\u001b[1;32m     35\u001b[0m \u001b[38;5;124;03m:return: Matrix with res[i][j]  = cos_sim(a[i], b[j])\u001b[39;00m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(a, torch\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[0;32m---> 38\u001b[0m     a \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(b, torch\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[1;32m     41\u001b[0m     b \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(b)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import random\n",
    "import json\n",
    "\n",
    "# Définition des poids à tester\n",
    "weights_to_try = {\n",
    "    \"Titre\": [0.5,0.7,1.3,1.5,1.7,1.9,2,2],\n",
    "    \"Description\": [0.5,0.7,1.3,1.5,1.7,1.9,2,2],\n",
    "    \"Application\": [0.5,0.7,1.3,1.5,1.7,1.9,2,2],\n",
    "    \"Bilan énergétique\": [0.5,0.7,1.3,1.5,1.7,1.9,2,2],\n",
    "    \"Titre technologie\": [0.5,0.7,1.3,1.5,1.7,1.9,2,2],\n",
    "    \"Description technologie\": [0.5,0.7,1.3,1.5,1.7,1.9,2,2],\n",
    "}\n",
    "\n",
    "best_accuracy_top_1 = 0.0\n",
    "best_accuracy_top_3 = 0.0\n",
    "best_weights = None\n",
    "num_iterations = 1500  # Nombre d'itérations pour la recherche aléatoire\n",
    "\n",
    "def save_best_model(best_accuracy, best_weights, path):\n",
    "    with open(path, \"w\") as f:\n",
    "        model_data = {\n",
    "            \"best_accuracy\": best_accuracy,\n",
    "            \"best_weights\": best_weights\n",
    "        }\n",
    "        json.dump(model_data, f, indent=4)\n",
    "\n",
    "for _ in range(num_iterations):\n",
    "    # Générer une combinaison aléatoire de poids\n",
    "    weights = {key: random.choice(values) for key, values in weights_to_try.items()}\n",
    "    \n",
    "    # Calculer l'accuracy pour cette combinaison de poids\n",
    "    accuracy_top_1 = test_accuracy(path_embedding_file, df_testset, top_n=1)\n",
    "    accuracy_top_3 = test_accuracy(path_embedding_file, df_testset, top_n=3)\n",
    "\n",
    "    # Vérifier si c'est la meilleure accuracy jusqu'à présent\n",
    "    if accuracy_top_1 > best_accuracy_top_1:\n",
    "        best_accuracy_top_1 = accuracy_top_1\n",
    "        print(\"Best accuracy : \", best_accuracy_top_1)\n",
    "        best_weights = weights.copy()\n",
    "        print(\"Best weight : \", best_weights)\n",
    "        # Sauvegarder les meilleurs poids et l'accuracy dans un fichier\n",
    "        save_best_model(best_accuracy_top_1, best_weights, \"best_weights_camembert_top_1.json\")\n",
    "\n",
    "    # Vérifier si c'est la meilleure accuracy jusqu'à présent\n",
    "    if accuracy_top_3 > best_accuracy_top_3:\n",
    "        best_accuracy_top_3 = accuracy_top_3\n",
    "        print(\"Best accuracy : \", best_accuracy_top_3)\n",
    "        best_weights = weights.copy()\n",
    "        print(\"Best weight : \", best_weights)\n",
    "        # Sauvegarder les meilleurs poids et l'accuracy dans un fichier\n",
    "        save_best_model(best_accuracy_top_3, best_weights, \"best_weights_camembert_top_3.json\")\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
