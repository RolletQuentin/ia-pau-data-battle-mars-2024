{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modèle 1 : Architecture comparaison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Définition d'une procédure de test\n",
    "\n",
    "**Dataset :**\n",
    "\n",
    "Afin de pouvoir comparer nos architectures et par la suite nos modèles, nous avons généré un dataset d'entrainement.\n",
    "Nous avons utilisé Chat-GPT en lui donnant des Id_solution ainsi que toutes les informations que nous utilisons dans notre modèle (Titre, Description, Bilan énergie) afin qu'il génère des requêtes qu'un utilisateur aurrait pu formuler en fonction de ces solutions. Nous avons tiré les id_solution de manière aléatoire afin d'avoir une répartition des question homogène sur le dataset. Nous n'avons pas de doublons d'id_solution dans le dataset.\n",
    "\n",
    "**Méthode de test :**\n",
    "\n",
    "Afin de tester l'accuracy de nos modèles, nous avons choisi de faire des inférence sur notre dataset de test et de compter 1 point si l'id_solution réel est prédit en première position et 0 point sinon. Ensuite on divise par le nombre de données dans le dataset afin d'avoir une valeur d'accuracy entre 0 et 1.\n",
    "\n",
    "Il est evident que notre modèle prédira en 2, 3, ... positions d'autres résultats pertinents que l'utilisateur pourrait étudier, mais cela n'étant pas évident à quantifier dans un premier test automatique, nous avons choisi de ne pas le traiter pour le moment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tests\n",
    "\n",
    "Les codes de ces trois architectures utilisant des fonctions similaires mais avec quelques subtiles adaptations, nous avons préféré lancer les tests dans chacun des fichiers .ipynb de nos architecture et recensé les résultats ici."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/patrice/Documents/Etudes/CY-Tech/Ing2_Sem2_2023-2024/UE7_Projet_DataBattle_IA-Pau/ia-pau-data-battle-mars-2024/backend/venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import unicodedata\n",
    "import spacy\n",
    "from bs4 import BeautifulSoup\n",
    "from spacy.lang.fr.stop_words import STOP_WORDS\n",
    "import pickle\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from sentence_transformers.quantization import quantize_embeddings\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Anciennes fonctions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Commun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_average_embedding(text, quantize=False, precision=\"binary\"):\n",
    "    # Diviser le texte en phrases\n",
    "    sentences = [sentence.strip() for sentence in text.split('.') if sentence.strip()]\n",
    "    \n",
    "    # Calculer l'embedding de chaque phrase\n",
    "    if quantize :\n",
    "        sentence_embeddings = model.encode(sentences, precision=precision)\n",
    "    else :\n",
    "        sentence_embeddings = model.encode(sentences)\n",
    "    \n",
    "    # Prendre la moyenne des embeddings des phrases\n",
    "    if len(sentence_embeddings) > 0:\n",
    "        average_embedding = np.mean(sentence_embeddings, axis=0)\n",
    "    else:\n",
    "        average_embedding = np.zeros(model.get_sentence_embedding_dimension())\n",
    "    \n",
    "    return average_embedding\n",
    "\n",
    "def pre_processing(texte):\n",
    "    # Nettoyer HTML Tags\n",
    "    texte = BeautifulSoup(texte, 'html.parser').get_text()\n",
    "\n",
    "    # Remplacer \"&nbsp;.\" par rien\n",
    "    texte = re.sub(r'&nbsp;\\.', '', texte)\n",
    "\n",
    "    # Accents\n",
    "    texte = unicodedata.normalize('NFD', texte).encode('ascii', 'ignore').decode(\"utf-8\")\n",
    "\n",
    "    # Retirer les numéros\n",
    "    texte = re.sub(r'\\b\\d+\\b', '', texte)\n",
    "\n",
    "    # Tokenization, Lemmatization, Removing Stopwords, Lowercase\n",
    "    doc = nlp(texte)\n",
    "    phrases_propres = []\n",
    "    for phrase in doc.sents:\n",
    "        tokens = [token.lemma_.lower() for token in phrase if not token.is_stop and not token.is_punct and not token.is_space]\n",
    "        phrase_propre = ' '.join(tokens)\n",
    "        if phrase_propre:\n",
    "            phrases_propres.append(phrase_propre + \".\")  # Ajouter un point à la fin de la phrase propre\n",
    "\n",
    "    # Joining the cleaned sentences back into a single string\n",
    "    cleaned_text = ' '.join(phrases_propres)\n",
    "\n",
    "    return cleaned_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Architecture 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Architecture 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Architecture 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_processing_sol_archi3(sentences):\n",
    "    phrases_propres = []\n",
    "    for texte in sentences:\n",
    "        # Nettoyer HTML Tags\n",
    "        texte = BeautifulSoup(texte, 'html.parser').get_text()\n",
    "        # Remplacer \"&nbsp;.\" par rien\n",
    "        texte = re.sub(r'&nbsp;\\.', '', texte)\n",
    "        # Accents\n",
    "        texte = unicodedata.normalize('NFD', texte).encode('ascii', 'ignore').decode(\"utf-8\")\n",
    "        # Retirer les numéros\n",
    "        texte = re.sub(r'\\b\\d+\\b', '', texte)\n",
    "        # Tokenization, Lemmatization, Removing Stopwords, Lowercase\n",
    "        doc = nlp(texte)\n",
    "        for phrase in doc.sents:\n",
    "            tokens = [token.lemma_.lower() for token in phrase if not token.is_stop and not token.is_punct and not token.is_space]\n",
    "            phrase_propre = ' '.join(tokens)\n",
    "            if phrase_propre:\n",
    "                phrases_propres.append(phrase_propre)\n",
    "    return phrases_propres\n",
    "\n",
    "def load_and_merge_data_archi3(csv_file = '../data/solutions.csv'):\n",
    "    # Charger le fichier CSV en spécifiant le séparateur '|'\n",
    "    df = pd.read_csv(csv_file, sep='|', header=None)\n",
    "    # Renommer les colonnes\n",
    "    df.columns = ['id_solution', 'categorie', 'texte']\n",
    "    # Filtrer les lignes pour les catégories spécifiées\n",
    "    categories_specifiees = [1, 2, 5, 6]\n",
    "    df_filtre = df[df['categorie'].isin(categories_specifiees)]\n",
    "    # Pivoter les données pour obtenir les colonnes 'titre', 'definition', 'application' et 'bilan énergie'\n",
    "    df_pivot = df_filtre.pivot(index='id_solution', columns='categorie', values='texte').reset_index()\n",
    "    # Renommer les colonnes\n",
    "    df_pivot.columns = ['id_solution', 'titre', 'definition', 'application', 'bilan_energie']\n",
    "    # Gérer les valeurs NaN lors de la fusion des colonnes\n",
    "    def combine_text(row):\n",
    "        text_parts = [row[col] for col in colonnes if pd.notnull(row[col])]\n",
    "        return text_parts\n",
    "    # Sélectionner uniquement les colonnes 'id_solution' et les champs requis\n",
    "    colonnes = ['titre', 'definition', 'application', 'bilan_energie']\n",
    "    df_pivot['champs'] = df_pivot.apply(combine_text, axis=1)\n",
    "    df_final = df_pivot[['id_solution', 'champs']]\n",
    "    # Convertir en liste de listes pour chaque ligne\n",
    "    result = df_final.values.tolist()\n",
    "    return result\n",
    "\n",
    "# NOUVELLE FONCTION\n",
    "def calculate_section_embedding_archi3(sentences, quantize=False, precision=\"binary\"):\n",
    "    # Calculer l'embedding de chaque phrase\n",
    "    if quantize :\n",
    "        sentence_embeddings = model.encode(sentences, precision=precision)\n",
    "    else :\n",
    "        sentence_embeddings = model.encode(sentences)\n",
    "    return sentence_embeddings\n",
    "\n",
    "def genere_embedding_archi3(data, output_file, quantize=False, precision=\"binary\"):\n",
    "    # Appliquer la fonction pour calculer l'embedding moyen à chaque texte\n",
    "    if quantize:\n",
    "        embeddings = data['clean_text'].apply(calculate_section_embedding, quantize=True)\n",
    "    else :\n",
    "        embeddings = data['clean_text'].apply(calculate_section_embedding)\n",
    "    # Créer un nouveau DataFrame avec id_solution et les embeddings\n",
    "    new_data = {\n",
    "        'id_solution': data['id_solution'],\n",
    "        'text_embedding': embeddings # Désormais mes embeddings sont des listes de solutions contenant chacune les vecteurs de toutes les phrases de la solution.\n",
    "    }\n",
    "    # Créer un DataFrame à partir des nouvelles données\n",
    "    df_embeddings = pd.DataFrame(new_data)\n",
    "    # Storer les embeddings dans un fichier\n",
    "    with open(output_file, \"wb\") as fOut:\n",
    "        pickle.dump(df_embeddings, fOut, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    print(\"Les embeddings ont été storer avec succès.\")\n",
    "\n",
    "\n",
    "def find_solution_archi3(text_to_compare, embeddings_file, quantize=False, precision=\"binary\"):\n",
    "    # Calculer l'embedding moyen du texte à comparer\n",
    "    embedding_to_compare = calculate_average_embedding(text_to_compare, quantize, precision)\n",
    "    # Charger les embeddings à partir du fichier\n",
    "    with open(embeddings_file, \"rb\") as fIn:\n",
    "        df_embeddings = pickle.load(fIn)\n",
    "    list_similarities = []\n",
    "    # Pour chaque solution\n",
    "    for solution in df_embeddings['text_embedding'].values:\n",
    "        embeddings_array = np.stack(solution)\n",
    "        # Calculer la similarité cosinus entre l'embedding à comparer et les embeddings dans df_embeddings\n",
    "        similarities = util.pytorch_cos_sim(embedding_to_compare.reshape(1, -1), embeddings_array)\n",
    "        max_value, _ = similarities.max(dim=1)\n",
    "        list_similarities.append(max_value)\n",
    "    # Ajouter les similarités au DataFrame df_embeddings\n",
    "    df_embeddings['similarity'] = list_similarities\n",
    "    # Trier par similarité décroissante\n",
    "    df_sorted = df_embeddings.sort_values(by='similarity', ascending=False)\n",
    "    # Récupérer les id_solution et les similarités\n",
    "    solution_info = df_sorted[['id_solution', 'similarity']].head(10)\n",
    "    # Convertir en liste de tuples (id_solution, similarity)\n",
    "    solution_list = list(zip(solution_info['id_solution'], solution_info['similarity']))\n",
    "    return solution_list\n",
    "\n",
    "# Fonction appelé par notre utilisateur\n",
    "def model_PAT_archi3(secteur, description, embedding_name) :\n",
    "    # On commence par concaténer notre secteur et notre description.\n",
    "    text = secteur + \". \" + description\n",
    "    # Ensuite on applique notre pré-processing\n",
    "    clean_text = pre_processing(text)\n",
    "    # Ensuite on cherche nos similarités \n",
    "    solutions = find_solution_archi3(clean_text, embedding_name)\n",
    "    # On return une liste contenant uniquement le numéros des solutions\n",
    "    id_solutions = []\n",
    "    for solution in solutions :\n",
    "        id_solutions.append(solution[0])\n",
    "    return id_solutions\n",
    "\n",
    "df_solution_archi3 = load_and_merge_data_archi3()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Récupération de quelques données aléatoire pour générer notre dataset dans ChatGPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Id solution :  249 \n",
      "Description :  ['Moteur à haut rendement label IE2 (EFF1)']\n",
      "Id solution :  167 \n",
      "Description :  ['Participation du personnel dans la recherche de fuite', 'Le personnel qui travaille directement sur les lignes de production&nbsp;est id&eacute;alement plac&eacute; pour identifier les fuites&nbsp;en premier.&nbsp;De ce fait, l&rsquo;implication du personnel dans la recherche de fuites sur le r&eacute;seau d&rsquo;air comprim&eacute; peut aider &agrave; en optimiser le fonctionnement. Le personnel sensibilis&eacute; travaillant peut faire remonter l&rsquo;information lorsqu&rsquo;il se rend compte d&rsquo;une fuite d&rsquo;air sur le r&eacute;seau ou de la d&eacute;faillance d&rsquo;une soufflette. Des explications compl&eacute;mentaires sur la mani&egrave;re de d&eacute;tecter les fuites peuvent &ecirc;tre n&eacute;cessaires. &nbsp;', \"La solution est applicable à tous le sites industriels utilisant de l'air comprimé.&nbsp;Du fait du nombre de personnel élevé, l'identification des fuites est particulièrement applicable sur les lignes de montage et de conditonnement\"]\n",
      "Id solution :  547 \n",
      "Description :  ['Chaudière collective de type basse température']\n",
      "Id solution :  230 \n",
      "Description :  ['Horloge astronomique', 'L’horloge astronomique permet de couper automatiquement l’éclairage lorsque le jour se lève. Les calculateurs astronomiques radio-synchronisés assurent la synchronisation des allumages. Ils gèrent les temps d’allumage à l’aide de programmations et sont souvent être couplés à des systèmes de variation de tension, de régulation ou de télégestion. &nbsp;', \"La solution est applicable aux systèmes d'éclairage extérieur ou intérieur&nbsp;lorsqu'un fort&nbsp;apport de&nbsp;lumière naturel existe. Ce type de régulation est généralement installé : dans l'industrie,&nbsp;sur les eclairages extérieurs au niveau des zones logistiques, dans le tertiaire au niveau des parkings, dans les collectivités pour l'éclairage public.\"]\n",
      "Id solution :  201 \n",
      "Description :  [\"Ajout ou réparation des réfractaires d'une chaudière vapeur\", \"Les mat&eacute;riaux r&eacute;fractaires servent &agrave; &eacute;viter non seulement les pertes thermiques mais aussi l'&eacute;chappement des fum&eacute;es de combustion. Chaque r&eacute;fractaire est adapt&eacute; &agrave; l'op&eacute;ration mise en oeuvre. Plusieurs facteurs influencent la qualit&eacute; du r&eacute;fractaire lors de sa conception: la quantit&eacute; d'eau, le type d'eau, la qualit&eacute; de l'op&eacute;ration de m&eacute;lange, l'&eacute;tape de durcissement. Lors du remplacement d'un mat&eacute;riau r&eacute;fractaire vieillisant, les raisons de la d&eacute;faillance du mat&eacute;riau doivent &ecirc;tre analys&eacute;es de mani&egrave;re &agrave; choisir un mat&eacute;riau plus ad&eacute;quat si n&eacute;cessaire. Quelques exemples de questions &agrave; se poser:&nbsp; Le mat&eacute;riau s'est-il &eacute;caill&eacute; &agrave; cause d'un choc thermique ? Le mat&eacute;riau s'est-il effrit&eacute; &agrave; cause de temp&eacute;ratures au-del&agrave; de sa limite d'utilisation ( c'est souvent le cas si la surface appara&icirc;t vitreuse) &nbsp;\", \"Cettes solution est applicable aux chaudières vapeur, principalement dans l'industrie.\", \"Une maintenance planifiée, une utilisation appropriée du type de matériau réfractaire et des procédures d'installation adéquates permettent de limiter au maximum les pertes énergétiques liée à cette isolation thermique. Un matériau réfractaire bien entretenu permet d'éviter des pertes de chaleur par radiation et par convection.\"]\n",
      "Id solution :  1670 \n",
      "Description :  ['Optimiser le stockage des déchets']\n",
      "Id solution :  863 \n",
      "Description :  ['LED pour la signalisation tricolore', \"Installation de diodes &eacute;lectroluminescentes (LED) dans la signalisation tricolore. Pour les signalisations tricolores (feux, passages pi&eacute;tons, panneaux d'avertissement clignotants, etc), les ampoules classiques sont de plus en plus remplac&eacute;es par des LED : elles prennent moins de place, sont plus efficaces et plus &eacute;conomes en &eacute;nergie.\", \"Les LED sont de plus en plus utilis&eacute;es dans la signalisation tricolores dans le monde entier. A Los Angeles, en 2014, tous les syst&egrave;mes d'&eacute;clairage urbain seront remplac&eacute;s par des LED, ce qui permettra &agrave; la ville de r&eacute;aliser environ $50 millions d'&eacute;conomie et de r&eacute;duire les GES de 40 000 tCO2.\", \"Les LED consomment environ 60% d'&eacute;nergie en moins que des ampoules classiques et ont une dur&eacute;e de vie 2 &agrave; 5 fois plus longue. Les co&ucirc;ts de maintenance sont &eacute;galement r&eacute;duits. Ainsi, les &eacute;conomies d'&eacute;nergie (&eacute;lectricit&eacute;) et financi&egrave;res r&eacute;alis&eacute;es chaque ann&eacute;e sont importantes.\"]\n",
      "Id solution :  1506 \n",
      "Description :  ['Presse à injecter hybride en remplacement de presse hydraulique', \"Installation d'une presse à injecter électrique (ou hybride)\"]\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[44], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m10\u001b[39m):\n\u001b[1;32m      6\u001b[0m     id_solution \u001b[38;5;241m=\u001b[39m random\u001b[38;5;241m.\u001b[39mrandint(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1400\u001b[39m)\n\u001b[0;32m----> 7\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\u001b[43mdf_solutions\u001b[49m\u001b[43m[\u001b[49m\u001b[43mid_solution\u001b[49m\u001b[43m]\u001b[49m):\n\u001b[1;32m      8\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mId solution : \u001b[39m\u001b[38;5;124m\"\u001b[39m, df_solutions[id_solution][\u001b[38;5;241m0\u001b[39m], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mDescription : \u001b[39m\u001b[38;5;124m\"\u001b[39m, df_solutions[id_solution][\u001b[38;5;241m1\u001b[39m])\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "# Chargement et fusion des données (simulation)\n",
    "df_solutions = load_and_merge_data_archi3()\n",
    "\n",
    "# Générer et afficher 5 identifiants de solution aléatoires\n",
    "for _ in range(10):\n",
    "    id_solution = random.randint(0, 1400)\n",
    "    if (df_solutions[id_solution]):\n",
    "        print(\"Id solution : \", df_solutions[id_solution][0], \"\\nDescription : \", df_solutions[id_solution][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chargement du dataset de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lire le fichier CSV\n",
    "df_testset = pd.read_csv(\"data/patrice_test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New fonction accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrée :\n",
    "# nom_model = nom du model à tester. Attention, nous devons avoir généré l'embedding dans /embeddings\n",
    "# dataset = dataset sur lequel on souhaite réaliser le test \n",
    "# top_n = integer du rang à partir du quel on considère une solution valide. 1 <=> seulement si top 1, 2 <=> top 1 ou 2 , ...\n",
    "def test_accuracy(embedding_name, dataset=df_testset, top_n=1) :\n",
    "    accuracy = 0\n",
    "    for i in range(1,len(dataset)):\n",
    "        predictions = model_PAT_archi3(\"\", dataset['Description'][i], embedding_name)\n",
    "        if (dataset[\"id_solution\"][i] in predictions[:top_n]):\n",
    "            accuracy += 1/len(dataset)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test architecture\n",
    "\n",
    "Afin de pouvoir comparer nos architecture nous avons choisi un modèle. Notre étude préliminaire nous a permis de déterminer que deux modèles multilingue sortaient du lot : mpnet-base-v2 et LaBSE. Pour notre étude d'architecture nous avons du fixer un modèle de manière arbitraire, ici nous avons choisi d'utiliser mpnet-base-v2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charger le modèle spaCy pour le français\n",
    "nlp = spacy.load(\"fr_core_news_sm\")\n",
    "# Charger le modèle\n",
    "model = SentenceTransformer(\"paraphrase-multilingual-mpnet-base-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "liste_architecture = {\"Architecture 1\" : \"paraphrase-multilingual-mpnet-base-v2_embeddings.pkl\", \"Architecture 2\" : \"Architecure-2_paraphrase-multilingual-mpnet-base-v2_embeddings.pkl\", \"Architecture 3\" : \"Architecure-3_paraphrase-multilingual-mpnet-base-v2_embeddings.pkl\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calcul d'accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'paraphrase-multilingual-mpnet-base-v2_embeddings.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[54], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtest_accuracy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mliste_architecture\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mArchitecture 1\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[53], line 8\u001b[0m, in \u001b[0;36mtest_accuracy\u001b[0;34m(embedding_name, dataset, top_n)\u001b[0m\n\u001b[1;32m      6\u001b[0m accuracy \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;28mlen\u001b[39m(dataset)):\n\u001b[0;32m----> 8\u001b[0m     predictions \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_PAT_archi3\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mDescription\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (dataset[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid_solution\u001b[39m\u001b[38;5;124m\"\u001b[39m][i] \u001b[38;5;129;01min\u001b[39;00m predictions[:top_n]):\n\u001b[1;32m     10\u001b[0m         accuracy \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;28mlen\u001b[39m(dataset)\n",
      "Cell \u001b[0;32mIn[52], line 69\u001b[0m, in \u001b[0;36mmodel_PAT_archi3\u001b[0;34m(secteur, description, embedding_name)\u001b[0m\n\u001b[1;32m     67\u001b[0m clean_text \u001b[38;5;241m=\u001b[39m pre_processing(text)\n\u001b[1;32m     68\u001b[0m \u001b[38;5;66;03m# Ensuite on cherche nos similarités \u001b[39;00m\n\u001b[0;32m---> 69\u001b[0m solutions \u001b[38;5;241m=\u001b[39m \u001b[43mfind_solution_archi3\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclean_text\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;66;03m# On return une liste contenant uniquement le numéros des solutions\u001b[39;00m\n\u001b[1;32m     71\u001b[0m id_solutions \u001b[38;5;241m=\u001b[39m []\n",
      "Cell \u001b[0;32mIn[52], line 34\u001b[0m, in \u001b[0;36mfind_solution_archi3\u001b[0;34m(text_to_compare, embeddings_file, quantize, precision)\u001b[0m\n\u001b[1;32m     31\u001b[0m embedding_to_compare \u001b[38;5;241m=\u001b[39m calculate_average_embedding(text_to_compare, quantize, precision)\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m# Charger les embeddings à partir du fichier\u001b[39;00m\n\u001b[0;32m---> 34\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43membeddings_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m fIn:\n\u001b[1;32m     35\u001b[0m     df_embeddings \u001b[38;5;241m=\u001b[39m pickle\u001b[38;5;241m.\u001b[39mload(fIn)\n\u001b[1;32m     38\u001b[0m list_similarities \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m~/Documents/Etudes/CY-Tech/Ing2_Sem2_2023-2024/UE7_Projet_DataBattle_IA-Pau/ia-pau-data-battle-mars-2024/backend/venv/lib/python3.11/site-packages/IPython/core/interactiveshell.py:324\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    318\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    319\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    320\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    321\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    322\u001b[0m     )\n\u001b[0;32m--> 324\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'paraphrase-multilingual-mpnet-base-v2_embeddings.pkl'"
     ]
    }
   ],
   "source": [
    "test_accuracy(liste_architecture[\"Architecture 1\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
