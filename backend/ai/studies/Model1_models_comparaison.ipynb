{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modèle 1 : Models Comparaison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notre étude va se dérouler en plusieurs parties. \n",
    "\n",
    "1. Mise en place d'un modèle de base :\n",
    "\n",
    "    **pre_traitement()**\n",
    "\n",
    "    Entrée : nos csv\n",
    "    \n",
    "    Sortie : Une matrice contenant les données que nous pensons utile pour ce modèle après avoir enlevé les stop_words, la ponctuation et les majuscules.\n",
    "\n",
    "    \n",
    "    **Choix d'un modèle de base**\n",
    "\n",
    "    **genere_embedding()**\n",
    "\n",
    "    Entrée : la sortie de pre_traitement()\n",
    "    \n",
    "    Sortie : stock dans un fichier les embeddings correspondant à nos solutions.\n",
    "\n",
    "    **find_solution()**\n",
    "\n",
    "    Entrée : secteur, description\n",
    "\n",
    "    Sortie : Une liste des meilleures solutions classés dans l'orde. On peut imaginer mettre une limite par exemple distance cos > 0.65\n",
    "\n",
    "    **Tester conso dans gaia**\n",
    "\n",
    "2. Creation d'un Test set \n",
    "\n",
    "    **Creation du test_set**\n",
    "\n",
    "    On génère des description et domaine d'activité en fonction des infos de solution avec GPT4. On génère différent niveau de précision par solution.\n",
    "\n",
    "    **test_model()**\n",
    "\n",
    "    Entrée : find_solution() de notre modèle et test_set.\n",
    "\n",
    "    Sortie : On renvoie une accuracy. On considère que si le modèle prédit la bonne solution dans son top 3 sol, c'est validé.\n",
    "\n",
    "3. Test de différents modèles. L'idée est d'avoir un tableau avec la conso, l'accuracy et le model pour expliquer pourquoi on a pris celui-ci plutôt qu'un autre.\n",
    "\n",
    "    **Faire un tableau de tests**\n",
    "    \n",
    "    Tester différents modèles et type de modèles, Word2Vec, FastText, SentenceTransformers (plusieurs).\n",
    "    \n",
    "    **Test Fine tuning**\n",
    "    \n",
    "    Fine tunner le meilleur pour voir le résultat.\n",
    "\n",
    "    **Si temps, on peut même tenter d'entrainer un modèle sur notre test set avec notre méthode**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Génération test set \n",
    "\n",
    "En utilisant GPT4, prendre des lots de 20 solutions, générer doaine d'activité et description de ce qu'un utilisateur pourrait demander. En générer 3 ou 4 par solutions avec différents niveau de précision. Le faire pour une centaine de solutions.\n",
    "\n",
    "On aurrait donc X = [description, domaine_activitée], y = [num_solution ].\n",
    "\n",
    "Pour tester notre modèle on peut tenter de lui faire prédire les meilleures solutions en fonction de la description et du domaine_activitée. Si la solution correspondante est dans le top 3 des solutions prédites, on considère que c'est une réussite."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Modèles à tester\n",
    "\n",
    "\n",
    "TF-IDF (c'est long et peu performant mais méthode sans embedding. On peut en parler dans Questionnaire et dire qu'on ne l'a pas implémenté car peu pertinent suivant les études qu'on a lu.)\n",
    "\n",
    "FastText (on a un token par mot et on fait la moyenne pour avoir le texte)\n",
    "\n",
    "Sentence transformers (un token par phrase et on fait la moyenne pour avoir le texte)\n",
    "\n",
    "Doc2Vec (document lvl)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
