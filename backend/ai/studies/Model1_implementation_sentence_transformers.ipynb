{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modèle 1 : Implémentation d'un Sentence Transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intallation et import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pandas spacy bs4 sentence_transformers numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import unicodedata\n",
    "import spacy\n",
    "from bs4 import BeautifulSoup\n",
    "from spacy.lang.fr.stop_words import STOP_WORDS\n",
    "import pickle\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from sentence_transformers.quantization import quantize_embeddings\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chardement des données\n",
    "\n",
    "L'objectif de cette partie est de lire les fichiers .csv contenu dans le dossier data, d'en extraire les données pertinentes et de renvoyer un dataset propre contenant [num_solution, données_pertinentes_concaténées].\n",
    "\n",
    "Dans un premier temps nous avons choisi de garder ces données sur nos solutions : 'titre', 'definition', 'application', 'bilan_energie'.\n",
    "\n",
    "**Il peut être pertinent de tester d'inclure plus de données sur les technologies par exemple.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_merge_data(csv_file = '../data/solutions.csv'):\n",
    "    # Charger le fichier CSV en spécifiant le séparateur '|'\n",
    "    df = pd.read_csv(csv_file, sep='|', header=None)\n",
    "    # Renommer les colonnes\n",
    "    df.columns = ['id_solution', 'categorie', 'texte']\n",
    "    # Filtrer les lignes pour les catégories spécifiées\n",
    "    categories_specifiees = [1, 2, 5, 6]\n",
    "    df_filtre = df[df['categorie'].isin(categories_specifiees)]\n",
    "    # Pivoter les données pour obtenir les colonnes 'titre', 'definition', 'application' et 'bilan énergie'\n",
    "    df_pivot = df_filtre.pivot(index='id_solution', columns='categorie', values='texte').reset_index()\n",
    "    # Renommer les colonnes\n",
    "    df_pivot.columns = ['id_solution', 'titre', 'definition', 'application', 'bilan_energie']\n",
    "\n",
    "    # Ajouter un point à la fin des colonnes si nécessaire\n",
    "    colonnes = ['titre', 'definition', 'application', 'bilan_energie']\n",
    "    for col in colonnes:\n",
    "        df_pivot[col] = df_pivot[col].apply(lambda x: x.strip() + '.' if isinstance(x, str) and x.strip()[-1] != '.' else x.strip() if isinstance(x, str) else x)\n",
    "    \n",
    "    # Gérer les valeurs NaN lors de la fusion des colonnes\n",
    "    def combine_text(row):\n",
    "        text_parts = [row[col] for col in colonnes if pd.notnull(row[col])]\n",
    "        return ' '.join(text_parts)\n",
    "    \n",
    "    # Appliquer la fonction pour créer la nouvelle colonne 'text'\n",
    "    df_pivot['text'] = df_pivot.apply(combine_text, axis=1)\n",
    "\n",
    "    # Sélectionner uniquement les colonnes 'id_solution' et 'text'\n",
    "    df_final = df_pivot[['id_solution', 'text']]\n",
    "    \n",
    "    return df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      id_solution                                               text\n",
      "0               2  Installation frigorifique négative de type cas...\n",
      "1               3  Centrale négative en mode booster. Lorsque l'i...\n",
      "2               4  Arrêt des compresseurs le week end et lorsque ...\n",
      "3               5  Régulation non électronique sur un compresseur...\n",
      "4               6  Condenseur frigorifique à haute efficacité. Mi...\n",
      "...           ...                                                ...\n",
      "1095         1710  Favoriser la communication digitale au catalog...\n",
      "1096         1711  Remplacer le chauffage des bains au gaz par un...\n",
      "1097         1712  Mettre en place des portes sectionnelles pour ...\n",
      "1098         1713          Films anti-chaleur sur les baies vitrées.\n",
      "1099         1714  Optimiser la production d'eau traitée (osmosé,...\n",
      "\n",
      "[1100 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Affachage des données chargées\n",
    "df_solutions = load_and_merge_data()\n",
    "print(df_solutions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pré-traitement des données\n",
    "\n",
    "Pour le pré-traitemment :\n",
    "- Nettoyer HTML tags\n",
    "- Remplacer \"&nbsp;.\" par rien. Cette balise correspond à une image dans la database.\n",
    "- Enlever les accents.\n",
    "- Retirer les numéros.\n",
    "- Tokenization\n",
    "- Lemmatization\n",
    "- Removing Stopwords\n",
    "- Lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charger le modèle spaCy pour le français\n",
    "nlp = spacy.load(\"fr_core_news_sm\")\n",
    "\n",
    "def pre_processing(texte):\n",
    "    # Nettoyer HTML Tags\n",
    "    texte = BeautifulSoup(texte, 'html.parser').get_text()\n",
    "\n",
    "    # Remplacer \"&nbsp;.\" par rien\n",
    "    texte = re.sub(r'&nbsp;\\.', '', texte)\n",
    "\n",
    "    # Accents\n",
    "    texte = unicodedata.normalize('NFD', texte).encode('ascii', 'ignore').decode(\"utf-8\")\n",
    "\n",
    "    # Retirer les numéros\n",
    "    texte = re.sub(r'\\b\\d+\\b', '', texte)\n",
    "\n",
    "    # Tokenization, Lemmatization, Removing Stopwords, Lowercase\n",
    "    doc = nlp(texte)\n",
    "    phrases_propres = []\n",
    "    for phrase in doc.sents:\n",
    "        tokens = [token.lemma_.lower() for token in phrase if not token.is_stop and not token.is_punct and not token.is_space]\n",
    "        phrase_propre = ' '.join(tokens)\n",
    "        if phrase_propre:\n",
    "            phrases_propres.append(phrase_propre + \".\")  # Ajouter un point à la fin de la phrase propre\n",
    "\n",
    "    # Joining the cleaned sentences back into a single string\n",
    "    cleaned_text = ' '.join(phrases_propres)\n",
    "\n",
    "    return cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text brut :\n",
      " Installation frigorifique négative de type cascade utilisant du CO2. Mise en place d'une installation frigorifique négative de type cascade utilisant du CO2 comme fluide frigorigène. Pour être éligible à CEE, la mise en place doit être effectuée par un professionnel et appliquée dans des locaux de commerce de distribution alimentaire de surface de vente inférieure à 5000 m². Comparé aux autres fluides frigorigènes, le CO2 est un fluide. \n",
      "Text pré-traité :\n",
      " installation frigorifique negativ type cascade utiliser co2. mise place installation frigorifique negativ type cascade utiliser co2 fluide frigorigene. eligibl cee mise place effectuee professionnel appliquee local commerce distribution alimentaire surface vente inferieure m. compare fluide frigorigene co2 fluide.\n"
     ]
    }
   ],
   "source": [
    "# Affichage des données nettoyées de la solution id_solution\n",
    "id_solution = 2\n",
    "\n",
    "text_brut = df_solutions[df_solutions['id_solution'] == id_solution]['text'].iloc[0]\n",
    "clean_text = pre_processing(text_brut)\n",
    "\n",
    "print(\"Text brut :\\n\", text_brut, \"\\nText pré-traité :\\n\",clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_221197/1761720504.py:6: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  texte = BeautifulSoup(texte, 'html.parser').get_text()\n"
     ]
    }
   ],
   "source": [
    "# Appliquons le traitement à la colonne text de notre df_solutions\n",
    "df_solutions['clean_text'] = df_solutions['text'].apply(pre_processing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choix du modèle\n",
    "\n",
    "Nous vons choisi d'implémenter le modèle **paraphrase-multilingual-MiniLM-L12-v2** qui est un modèle multi-lingual (+50 languages).\n",
    "- Max sequence Length : 128 (au dela les mots sont cropés.)\n",
    "- Dimensions : 384\n",
    "- Suitable Score Functions: cosine-similarity (util.cos_sim)\n",
    "\n",
    "Source : https://huggingface.co/sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\n",
    "\n",
    "**Il serait pertinent d'essayer des modèles spécialisés en Français tel que CamemBert.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charger le modèle\n",
    "model = SentenceTransformer(\"paraphrase-multilingual-MiniLM-L12-v2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calcul de l'embedding\n",
    "\n",
    "On définit une fonction *calculate_average_embedding()* qui prend un text en entrée et retourne la moyenne de l'embedding de ses phrases. \n",
    "\n",
    "Nous faisons cela afin de ne pas cropper nos données car la max-sequence-length est de 128 sur ce modèle et nos données pouvant être particulièrement longues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_average_embedding(text, quantize=False, precision=\"binary\"):\n",
    "    # Diviser le texte en phrases\n",
    "    sentences = [sentence.strip() for sentence in text.split('.') if sentence.strip()]\n",
    "    \n",
    "    # Calculer l'embedding de chaque phrase\n",
    "    if quantize :\n",
    "        sentence_embeddings = model.encode(sentences, precision=precision)\n",
    "    else :\n",
    "        sentence_embeddings = model.encode(sentences)\n",
    "    \n",
    "    # Prendre la moyenne des embeddings des phrases\n",
    "    if len(sentence_embeddings) > 0:\n",
    "        average_embedding = np.mean(sentence_embeddings, axis=0)\n",
    "    else:\n",
    "        average_embedding = np.zeros(model.get_sentence_embedding_dimension())\n",
    "    \n",
    "    return average_embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La fonction *genere_embedding()* nous permet de stocker nos embeddings une fois que nous les avons générés. Cela est particulièrement utile car leur génération prend 1\"30. Nous ne pouvons pas nous permettre de les regénérer à chaque requette que ferais l'utilisateur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def genere_embedding(data, output_file, quantize=False, precision=\"binary\"):\n",
    "\n",
    "    # Appliquer la fonction pour calculer l'embedding moyen à chaque texte\n",
    "    if quantize:\n",
    "        embeddings = data['clean_text'].apply(calculate_average_embedding, quantize=True)\n",
    "    else :\n",
    "        embeddings = data['clean_text'].apply(calculate_average_embedding)\n",
    "\n",
    "    \n",
    "    # Créer un nouveau DataFrame avec id_solution et les embeddings\n",
    "    new_data = {\n",
    "        'id_solution': data['id_solution'],\n",
    "        'text_embedding': embeddings\n",
    "    }\n",
    "    \n",
    "    # Créer un DataFrame à partir des nouvelles données\n",
    "    df_embeddings = pd.DataFrame(new_data)\n",
    "    \n",
    "    # Storer les embeddings dans un fichier\n",
    "    with open(output_file, \"wb\") as fOut:\n",
    "        pickle.dump(df_embeddings, fOut, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "    print(\"Les embeddings ont été storer avec succès.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Les embeddings ont été storer avec succès.\n"
     ]
    }
   ],
   "source": [
    "# Générons notre embedding\n",
    "genere_embedding(df_solutions, \"model1_embeddings.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calcul des solutions\n",
    "\n",
    "La fonction *find_solution()* prend en entrée un texte à comparer, calcul son embedding et retourne une liste contenant ses 10 plus proches [solutions, similarité].\n",
    "\n",
    "Attention à bien nettoyer le texte avec notre pré-processing avant de le passer à cette fonction.\n",
    "\n",
    "**Il peut être pertinent de renvoyer toutes les solutions > à une certaine similarité.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_solution(text_to_compare, embeddings_file, quantize=False, precision=\"binary\"):\n",
    "    # Calculer l'embedding moyen du texte à comparer\n",
    "    embedding_to_compare = calculate_average_embedding(text_to_compare, quantize, precision)\n",
    "    \n",
    "    # Charger les embeddings à partir du fichier\n",
    "    with open(embeddings_file, \"rb\") as fIn:\n",
    "        df_embeddings = pickle.load(fIn)\n",
    "    \n",
    "    # Calculer la similarité cosinus entre l'embedding à comparer et les embeddings dans df_embeddings\n",
    "    similarities = util.pytorch_cos_sim(embedding_to_compare.reshape(1, -1), df_embeddings['text_embedding'].values.tolist())\n",
    "    \n",
    "    # Ajouter les similarités au DataFrame df_embeddings\n",
    "    df_embeddings['similarity'] = similarities.flatten()\n",
    "    \n",
    "    # Trier par similarité décroissante\n",
    "    df_sorted = df_embeddings.sort_values(by='similarity', ascending=False)\n",
    "    \n",
    "    # Récupérer les id_solution et les similarités\n",
    "    solution_info = df_sorted[['id_solution', 'similarity']].head(10)\n",
    "    \n",
    "    # Convertir en liste de tuples (id_solution, similarity)\n",
    "    solution_list = list(zip(solution_info['id_solution'], solution_info['similarity']))\n",
    "    \n",
    "    return solution_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Les solutions les plus proches :\n",
      "id_solution : 3, Similarité : 1.0000001192092896\n",
      "id_solution : 42, Similarité : 0.8587038516998291\n",
      "id_solution : 867, Similarité : 0.829397439956665\n",
      "id_solution : 19, Similarité : 0.818574845790863\n",
      "id_solution : 922, Similarité : 0.8174538016319275\n",
      "id_solution : 35, Similarité : 0.8152481913566589\n",
      "id_solution : 354, Similarité : 0.8119463920593262\n",
      "id_solution : 28, Similarité : 0.8111556768417358\n",
      "id_solution : 918, Similarité : 0.8091707825660706\n",
      "id_solution : 25, Similarité : 0.8053005933761597\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/patrice/Documents/Etudes/CY-Tech/Ing2_Sem2_2023-2024/UE7_Projet_DataBattle_IA-Pau/ia-pau-data-battle-mars-2024/backend/venv/lib/python3.11/site-packages/sentence_transformers/util.py:41: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:275.)\n",
      "  b = torch.tensor(b)\n"
     ]
    }
   ],
   "source": [
    "# Exemple d'utilisation pour trouver les solutions les plus proches d'un nouveau texte\n",
    "# ici on a pris le texte correspondant à la solution 3. On doit trouver une similarité de 1.\n",
    "text_to_compare = \"centrale negativ mode booster. installation centrale frigorifique bas moyenne temperatur mode booster consister injecter refoulement compresseur froid negatif aspiration compresseur cycle froid positif. maniere rendement cycle frigorifique bas temperature negatif grandement ameliore condensation bas temperature egal temperature evaporation central positif. solution diminuer quantite tuyauterie utilisee. solution applicable uniquement projet neuf projet refonte total systeme production froid. eligibl production froid niveau temperature. production froid positif temperature consigne 0c temperature evaporation cote fluide -10c exemple. production froid negatif temperature consigne bien inferieur 0c temperature evaporation c exemple. besoin froid positif superieur besoin froid negatif. niveau temperature exempe retrouve secteur activite grande moyenne surface distribution alimentaire gms. industrie agroalimentaire. chimie pharmacie.\"\n",
    "solutions = find_solution(text_to_compare, \"model1_embeddings.pkl\")\n",
    "\n",
    "# Afficher les solutions les plus proches avec leurs similarités\n",
    "print(\"Les solutions les plus proches :\")\n",
    "for solution in solutions:\n",
    "    print(f\"id_solution : {solution[0]}, Similarité : {solution[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quantization\n",
    "\n",
    "On peut appliquer de la quantization afin de réduire la taille des embeddings stockés de sorte à réduire le temps d'accès à nos données ainsi que la taille du stockage nécessaire sur nos serveurs.\n",
    "\n",
    "Ici la quantization n'est pas pertinente car on passe d'un fichier embedding de 1.7MB à 459.6KB, on ne gagne pas de temps d'execution et on perd en précision de prédiction. Ce pourrait être utile si le nombre de solutions présents dans la BDD était bien plus grand, peut être à implémenté dans le futur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Les embeddings ont été storer avec succès.\n",
      "Les solutions les plus proches :\n",
      "id_solution : 3, Similarité : 1.0000000000000002\n",
      "id_solution : 280, Similarité : 0.8338601026755779\n",
      "id_solution : 26, Similarité : 0.8293075388193698\n",
      "id_solution : 108, Similarité : 0.8239859183736618\n",
      "id_solution : 958, Similarité : 0.8224887399894056\n",
      "id_solution : 354, Similarité : 0.8173533730067889\n",
      "id_solution : 1119, Similarité : 0.8071937765402742\n",
      "id_solution : 264, Similarité : 0.7943726247579588\n",
      "id_solution : 903, Similarité : 0.7862356686070046\n",
      "id_solution : 824, Similarité : 0.7855407449267934\n"
     ]
    }
   ],
   "source": [
    "genere_embedding(df_solutions, \"model1_embeddings_quantized.pkl\", quantize=True, precision=\"binary\")\n",
    "\n",
    "# Exemple d'utilisation pour trouver les solutions les plus proches d'un nouveau texte\n",
    "text_to_compare = \"centrale negativ mode booster. installation centrale frigorifique bas moyenne temperatur mode booster consister injecter refoulement compresseur froid negatif aspiration compresseur cycle froid positif. maniere rendement cycle frigorifique bas temperature negatif grandement ameliore condensation bas temperature egal temperature evaporation central positif. solution diminuer quantite tuyauterie utilisee. solution applicable uniquement projet neuf projet refonte total systeme production froid. eligibl production froid niveau temperature. production froid positif temperature consigne 0c temperature evaporation cote fluide -10c exemple. production froid negatif temperature consigne bien inferieur 0c temperature evaporation c exemple. besoin froid positif superieur besoin froid negatif. niveau temperature exempe retrouve secteur activite grande moyenne surface distribution alimentaire gms. industrie agroalimentaire. chimie pharmacie.\"\n",
    "solutions = find_solution(text_to_compare, \"model1_embeddings_quantized.pkl\", quantize=True)\n",
    "\n",
    "# Afficher les solutions les plus proches avec leurs similarités\n",
    "print(\"Les solutions les plus proches :\")\n",
    "for solution in solutions:\n",
    "    print(f\"id_solution : {solution[0]}, Similarité : {solution[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utilisation du modèle\n",
    "\n",
    "On définit ici le code qui va être executé lorsqu'un utilisateur va faire une requette.\n",
    "\n",
    "Pour simuler une requette, nous allons charger les données mises à notre disposition par IA Pau (Mail : Exemple de solutions).\n",
    "\n",
    "On voit que sur les données qu'IA Pau nous a fait parvenir, notre modèle ne semble pas très performant.\n",
    "\n",
    "**Il serait pertinent de générer notre propre dataset de test afin de pouvoir réaliser des tests plus avancés. De plus nous devons essayer d'autres modèles puis essayer de fine-tuner notre modèle.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Malheureusement nous n'avons pas reçu le domaine d'activité correspondant aux \n",
    "# requetes avec Kerdos.Et pour certaines requetes nous n'avons pas l'Id_solution non\n",
    "# plus, dans ce cas il est remplacé par -1.\n",
    "dataset_test_kerdos = [\n",
    "    [\"Id_solution\", \"Domaine_activite\", \"Description\"],\n",
    "    [724, \"\",\"C'est quoi la HP flottante ?\"],\n",
    "    [914, \"\", \"Je voudrais dimensionner un panneau solaire.\"],\n",
    "    [719, \"\", \"Quel gain pour un variateur de vitesse ?\"],\n",
    "    [-1, \"\", \"J'aimerais avoir une régulation optimisée de mon groupe froid.\"],\n",
    "    [-1, \"\", \"Comment faire pour réduire la consommation de mon compresseur d'air comprimé ?\"]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction appelé par notre utilisateur\n",
    "def model_PAT(secteur, description) :\n",
    "    # On commence par concaténer notre secteur et notre description.\n",
    "    text = secteur + \". \" + description\n",
    "\n",
    "    # Ensuite on applique notre pré-processing\n",
    "    clean_text = pre_processing(text)\n",
    "\n",
    "    # Ensuite on cherche nos similarités \n",
    "    solutions = find_solution(clean_text, \"embeddings.pkl\")\n",
    "\n",
    "    # On return une liste contenant uniquement le numéros des solutions\n",
    "    id_solutions = []\n",
    "    for solution in solutions :\n",
    "        id_solutions.append(solution[0])\n",
    "\n",
    "    return id_solutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------\n",
      "Solution attendue :  724\n",
      "[722, 54, 1070, 724, 386, 1144, 222, 335, 1533, 329]\n",
      "--------------------------------------------\n",
      "Solution attendue :  914\n",
      "[270, 1486, 1453, 1452, 1456, 1454, 1455, 1457, 1446, 1447]\n",
      "--------------------------------------------\n",
      "Solution attendue :  719\n",
      "[1533, 1445, 1144, 1140, 1649, 1595, 1596, 346, 54, 444]\n",
      "--------------------------------------------\n",
      "Solution attendue :  -1\n",
      "[1049, 149, 44, 803, 148, 5, 723, 3, 259, 483]\n",
      "--------------------------------------------\n",
      "Solution attendue :  -1\n",
      "[152, 154, 1056, 157, 145, 171, 502, 1001, 165, 153]\n"
     ]
    }
   ],
   "source": [
    "# On va tester sur notre dataset_test\n",
    "for i in range(1,len(dataset_test_kerdos)):\n",
    "    print(\"--------------------------------------------\")\n",
    "    print(\"Solution attendue : \", dataset_test_kerdos[i][0])\n",
    "    print(model_PAT(dataset_test_kerdos[i][1], dataset_test_kerdos[i][2]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
