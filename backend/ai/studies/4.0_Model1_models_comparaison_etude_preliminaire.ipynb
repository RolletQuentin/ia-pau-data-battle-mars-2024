{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modèle 1 : Models Comparaison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Librairies à installer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentencepiece in /home/patrice/Documents/Etudes/CY-Tech/Ing2_Sem2_2023-2024/UE7_Projet_DataBattle_IA-Pau/ia-pau-data-battle-mars-2024/backend/venv/lib/python3.11/site-packages (0.2.0)\n",
      "Requirement already satisfied: protobuf in /home/patrice/Documents/Etudes/CY-Tech/Ing2_Sem2_2023-2024/UE7_Projet_DataBattle_IA-Pau/ia-pau-data-battle-mars-2024/backend/venv/lib/python3.11/site-packages (5.26.0)\n"
     ]
    }
   ],
   "source": [
    "# Pour Camembert - Large\n",
    "!pip install sentencepiece protobuf\n",
    "import sentencepiece\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fonctions \n",
    "(prises dans Model1_implementation_sentence_transformers.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /home/patrice/Documents/Etudes/CY-Tech/Ing2_Sem2_2023-2024/UE7_Projet_DataBattle_IA-Pau/ia-pau-data-battle-mars-2024/backend/venv/lib/python3.11/site-packages (2.2.1)\n",
      "Requirement already satisfied: spacy in /home/patrice/Documents/Etudes/CY-Tech/Ing2_Sem2_2023-2024/UE7_Projet_DataBattle_IA-Pau/ia-pau-data-battle-mars-2024/backend/venv/lib/python3.11/site-packages (3.7.4)\n",
      "Requirement already satisfied: bs4 in /home/patrice/Documents/Etudes/CY-Tech/Ing2_Sem2_2023-2024/UE7_Projet_DataBattle_IA-Pau/ia-pau-data-battle-mars-2024/backend/venv/lib/python3.11/site-packages (0.0.2)\n",
      "Requirement already satisfied: sentence_transformers in /home/patrice/Documents/Etudes/CY-Tech/Ing2_Sem2_2023-2024/UE7_Projet_DataBattle_IA-Pau/ia-pau-data-battle-mars-2024/backend/venv/lib/python3.11/site-packages (2.6.0)\n",
      "Requirement already satisfied: numpy in /home/patrice/Documents/Etudes/CY-Tech/Ing2_Sem2_2023-2024/UE7_Projet_DataBattle_IA-Pau/ia-pau-data-battle-mars-2024/backend/venv/lib/python3.11/site-packages (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/patrice/Documents/Etudes/CY-Tech/Ing2_Sem2_2023-2024/UE7_Projet_DataBattle_IA-Pau/ia-pau-data-battle-mars-2024/backend/venv/lib/python3.11/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/patrice/Documents/Etudes/CY-Tech/Ing2_Sem2_2023-2024/UE7_Projet_DataBattle_IA-Pau/ia-pau-data-battle-mars-2024/backend/venv/lib/python3.11/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/patrice/Documents/Etudes/CY-Tech/Ing2_Sem2_2023-2024/UE7_Projet_DataBattle_IA-Pau/ia-pau-data-battle-mars-2024/backend/venv/lib/python3.11/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /home/patrice/Documents/Etudes/CY-Tech/Ing2_Sem2_2023-2024/UE7_Projet_DataBattle_IA-Pau/ia-pau-data-battle-mars-2024/backend/venv/lib/python3.11/site-packages (from spacy) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /home/patrice/Documents/Etudes/CY-Tech/Ing2_Sem2_2023-2024/UE7_Projet_DataBattle_IA-Pau/ia-pau-data-battle-mars-2024/backend/venv/lib/python3.11/site-packages (from spacy) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /home/patrice/Documents/Etudes/CY-Tech/Ing2_Sem2_2023-2024/UE7_Projet_DataBattle_IA-Pau/ia-pau-data-battle-mars-2024/backend/venv/lib/python3.11/site-packages (from spacy) (1.0.10)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /home/patrice/Documents/Etudes/CY-Tech/Ing2_Sem2_2023-2024/UE7_Projet_DataBattle_IA-Pau/ia-pau-data-battle-mars-2024/backend/venv/lib/python3.11/site-packages (from spacy) (2.0.8)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /home/patrice/Documents/Etudes/CY-Tech/Ing2_Sem2_2023-2024/UE7_Projet_DataBattle_IA-Pau/ia-pau-data-battle-mars-2024/backend/venv/lib/python3.11/site-packages (from spacy) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /home/patrice/Documents/Etudes/CY-Tech/Ing2_Sem2_2023-2024/UE7_Projet_DataBattle_IA-Pau/ia-pau-data-battle-mars-2024/backend/venv/lib/python3.11/site-packages (from spacy) (8.2.3)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /home/patrice/Documents/Etudes/CY-Tech/Ing2_Sem2_2023-2024/UE7_Projet_DataBattle_IA-Pau/ia-pau-data-battle-mars-2024/backend/venv/lib/python3.11/site-packages (from spacy) (1.1.2)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /home/patrice/Documents/Etudes/CY-Tech/Ing2_Sem2_2023-2024/UE7_Projet_DataBattle_IA-Pau/ia-pau-data-battle-mars-2024/backend/venv/lib/python3.11/site-packages (from spacy) (2.4.8)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /home/patrice/Documents/Etudes/CY-Tech/Ing2_Sem2_2023-2024/UE7_Projet_DataBattle_IA-Pau/ia-pau-data-battle-mars-2024/backend/venv/lib/python3.11/site-packages (from spacy) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in /home/patrice/Documents/Etudes/CY-Tech/Ing2_Sem2_2023-2024/UE7_Projet_DataBattle_IA-Pau/ia-pau-data-battle-mars-2024/backend/venv/lib/python3.11/site-packages (from spacy) (0.3.4)\n",
      "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /home/patrice/Documents/Etudes/CY-Tech/Ing2_Sem2_2023-2024/UE7_Projet_DataBattle_IA-Pau/ia-pau-data-battle-mars-2024/backend/venv/lib/python3.11/site-packages (from spacy) (0.9.4)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /home/patrice/Documents/Etudes/CY-Tech/Ing2_Sem2_2023-2024/UE7_Projet_DataBattle_IA-Pau/ia-pau-data-battle-mars-2024/backend/venv/lib/python3.11/site-packages (from spacy) (6.4.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /home/patrice/Documents/Etudes/CY-Tech/Ing2_Sem2_2023-2024/UE7_Projet_DataBattle_IA-Pau/ia-pau-data-battle-mars-2024/backend/venv/lib/python3.11/site-packages (from spacy) (4.66.2)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /home/patrice/Documents/Etudes/CY-Tech/Ing2_Sem2_2023-2024/UE7_Projet_DataBattle_IA-Pau/ia-pau-data-battle-mars-2024/backend/venv/lib/python3.11/site-packages (from spacy) (2.31.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /home/patrice/Documents/Etudes/CY-Tech/Ing2_Sem2_2023-2024/UE7_Projet_DataBattle_IA-Pau/ia-pau-data-battle-mars-2024/backend/venv/lib/python3.11/site-packages (from spacy) (2.6.1)\n",
      "Requirement already satisfied: jinja2 in /home/patrice/Documents/Etudes/CY-Tech/Ing2_Sem2_2023-2024/UE7_Projet_DataBattle_IA-Pau/ia-pau-data-battle-mars-2024/backend/venv/lib/python3.11/site-packages (from spacy) (3.1.3)\n",
      "Requirement already satisfied: setuptools in /home/patrice/Documents/Etudes/CY-Tech/Ing2_Sem2_2023-2024/UE7_Projet_DataBattle_IA-Pau/ia-pau-data-battle-mars-2024/backend/venv/lib/python3.11/site-packages (from spacy) (65.5.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/patrice/Documents/Etudes/CY-Tech/Ing2_Sem2_2023-2024/UE7_Projet_DataBattle_IA-Pau/ia-pau-data-battle-mars-2024/backend/venv/lib/python3.11/site-packages (from spacy) (24.0)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /home/patrice/Documents/Etudes/CY-Tech/Ing2_Sem2_2023-2024/UE7_Projet_DataBattle_IA-Pau/ia-pau-data-battle-mars-2024/backend/venv/lib/python3.11/site-packages (from spacy) (3.3.0)\n",
      "Requirement already satisfied: beautifulsoup4 in /home/patrice/Documents/Etudes/CY-Tech/Ing2_Sem2_2023-2024/UE7_Projet_DataBattle_IA-Pau/ia-pau-data-battle-mars-2024/backend/venv/lib/python3.11/site-packages (from bs4) (4.12.3)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.32.0 in /home/patrice/Documents/Etudes/CY-Tech/Ing2_Sem2_2023-2024/UE7_Projet_DataBattle_IA-Pau/ia-pau-data-battle-mars-2024/backend/venv/lib/python3.11/site-packages (from sentence_transformers) (4.39.1)\n",
      "Requirement already satisfied: torch>=1.11.0 in /home/patrice/Documents/Etudes/CY-Tech/Ing2_Sem2_2023-2024/UE7_Projet_DataBattle_IA-Pau/ia-pau-data-battle-mars-2024/backend/venv/lib/python3.11/site-packages (from sentence_transformers) (2.2.1)\n",
      "Requirement already satisfied: scikit-learn in /home/patrice/Documents/Etudes/CY-Tech/Ing2_Sem2_2023-2024/UE7_Projet_DataBattle_IA-Pau/ia-pau-data-battle-mars-2024/backend/venv/lib/python3.11/site-packages (from sentence_transformers) (1.4.1.post1)\n",
      "Requirement already satisfied: scipy in /home/patrice/Documents/Etudes/CY-Tech/Ing2_Sem2_2023-2024/UE7_Projet_DataBattle_IA-Pau/ia-pau-data-battle-mars-2024/backend/venv/lib/python3.11/site-packages (from sentence_transformers) (1.12.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.15.1 in /home/patrice/Documents/Etudes/CY-Tech/Ing2_Sem2_2023-2024/UE7_Projet_DataBattle_IA-Pau/ia-pau-data-battle-mars-2024/backend/venv/lib/python3.11/site-packages (from sentence_transformers) (0.21.4)\n",
      "Requirement already satisfied: Pillow in /home/patrice/Documents/Etudes/CY-Tech/Ing2_Sem2_2023-2024/UE7_Projet_DataBattle_IA-Pau/ia-pau-data-battle-mars-2024/backend/venv/lib/python3.11/site-packages (from sentence_transformers) (10.2.0)\n",
      "Requirement already satisfied: filelock in /home/patrice/Documents/Etudes/CY-Tech/Ing2_Sem2_2023-2024/UE7_Projet_DataBattle_IA-Pau/ia-pau-data-battle-mars-2024/backend/venv/lib/python3.11/site-packages (from huggingface-hub>=0.15.1->sentence_transformers) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/patrice/Documents/Etudes/CY-Tech/Ing2_Sem2_2023-2024/UE7_Projet_DataBattle_IA-Pau/ia-pau-data-battle-mars-2024/backend/venv/lib/python3.11/site-packages (from huggingface-hub>=0.15.1->sentence_transformers) (2024.3.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/patrice/Documents/Etudes/CY-Tech/Ing2_Sem2_2023-2024/UE7_Projet_DataBattle_IA-Pau/ia-pau-data-battle-mars-2024/backend/venv/lib/python3.11/site-packages (from huggingface-hub>=0.15.1->sentence_transformers) (6.0.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/patrice/Documents/Etudes/CY-Tech/Ing2_Sem2_2023-2024/UE7_Projet_DataBattle_IA-Pau/ia-pau-data-battle-mars-2024/backend/venv/lib/python3.11/site-packages (from huggingface-hub>=0.15.1->sentence_transformers) (4.9.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /home/patrice/Documents/Etudes/CY-Tech/Ing2_Sem2_2023-2024/UE7_Projet_DataBattle_IA-Pau/ia-pau-data-battle-mars-2024/backend/venv/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.16.2 in /home/patrice/Documents/Etudes/CY-Tech/Ing2_Sem2_2023-2024/UE7_Projet_DataBattle_IA-Pau/ia-pau-data-battle-mars-2024/backend/venv/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.16.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/patrice/Documents/Etudes/CY-Tech/Ing2_Sem2_2023-2024/UE7_Projet_DataBattle_IA-Pau/ia-pau-data-battle-mars-2024/backend/venv/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/patrice/Documents/Etudes/CY-Tech/Ing2_Sem2_2023-2024/UE7_Projet_DataBattle_IA-Pau/ia-pau-data-battle-mars-2024/backend/venv/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/patrice/Documents/Etudes/CY-Tech/Ing2_Sem2_2023-2024/UE7_Projet_DataBattle_IA-Pau/ia-pau-data-battle-mars-2024/backend/venv/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/patrice/Documents/Etudes/CY-Tech/Ing2_Sem2_2023-2024/UE7_Projet_DataBattle_IA-Pau/ia-pau-data-battle-mars-2024/backend/venv/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/patrice/Documents/Etudes/CY-Tech/Ing2_Sem2_2023-2024/UE7_Projet_DataBattle_IA-Pau/ia-pau-data-battle-mars-2024/backend/venv/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2024.2.2)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /home/patrice/Documents/Etudes/CY-Tech/Ing2_Sem2_2023-2024/UE7_Projet_DataBattle_IA-Pau/ia-pau-data-battle-mars-2024/backend/venv/lib/python3.11/site-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.7.11)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /home/patrice/Documents/Etudes/CY-Tech/Ing2_Sem2_2023-2024/UE7_Projet_DataBattle_IA-Pau/ia-pau-data-battle-mars-2024/backend/venv/lib/python3.11/site-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.1.4)\n",
      "Requirement already satisfied: sympy in /home/patrice/Documents/Etudes/CY-Tech/Ing2_Sem2_2023-2024/UE7_Projet_DataBattle_IA-Pau/ia-pau-data-battle-mars-2024/backend/venv/lib/python3.11/site-packages (from torch>=1.11.0->sentence_transformers) (1.12)\n",
      "Requirement already satisfied: networkx in /home/patrice/Documents/Etudes/CY-Tech/Ing2_Sem2_2023-2024/UE7_Projet_DataBattle_IA-Pau/ia-pau-data-battle-mars-2024/backend/venv/lib/python3.11/site-packages (from torch>=1.11.0->sentence_transformers) (3.2.1)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/patrice/Documents/Etudes/CY-Tech/Ing2_Sem2_2023-2024/UE7_Projet_DataBattle_IA-Pau/ia-pau-data-battle-mars-2024/backend/venv/lib/python3.11/site-packages (from torch>=1.11.0->sentence_transformers) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/patrice/Documents/Etudes/CY-Tech/Ing2_Sem2_2023-2024/UE7_Projet_DataBattle_IA-Pau/ia-pau-data-battle-mars-2024/backend/venv/lib/python3.11/site-packages (from torch>=1.11.0->sentence_transformers) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/patrice/Documents/Etudes/CY-Tech/Ing2_Sem2_2023-2024/UE7_Projet_DataBattle_IA-Pau/ia-pau-data-battle-mars-2024/backend/venv/lib/python3.11/site-packages (from torch>=1.11.0->sentence_transformers) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /home/patrice/Documents/Etudes/CY-Tech/Ing2_Sem2_2023-2024/UE7_Projet_DataBattle_IA-Pau/ia-pau-data-battle-mars-2024/backend/venv/lib/python3.11/site-packages (from torch>=1.11.0->sentence_transformers) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/patrice/Documents/Etudes/CY-Tech/Ing2_Sem2_2023-2024/UE7_Projet_DataBattle_IA-Pau/ia-pau-data-battle-mars-2024/backend/venv/lib/python3.11/site-packages (from torch>=1.11.0->sentence_transformers) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/patrice/Documents/Etudes/CY-Tech/Ing2_Sem2_2023-2024/UE7_Projet_DataBattle_IA-Pau/ia-pau-data-battle-mars-2024/backend/venv/lib/python3.11/site-packages (from torch>=1.11.0->sentence_transformers) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/patrice/Documents/Etudes/CY-Tech/Ing2_Sem2_2023-2024/UE7_Projet_DataBattle_IA-Pau/ia-pau-data-battle-mars-2024/backend/venv/lib/python3.11/site-packages (from torch>=1.11.0->sentence_transformers) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/patrice/Documents/Etudes/CY-Tech/Ing2_Sem2_2023-2024/UE7_Projet_DataBattle_IA-Pau/ia-pau-data-battle-mars-2024/backend/venv/lib/python3.11/site-packages (from torch>=1.11.0->sentence_transformers) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/patrice/Documents/Etudes/CY-Tech/Ing2_Sem2_2023-2024/UE7_Projet_DataBattle_IA-Pau/ia-pau-data-battle-mars-2024/backend/venv/lib/python3.11/site-packages (from torch>=1.11.0->sentence_transformers) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /home/patrice/Documents/Etudes/CY-Tech/Ing2_Sem2_2023-2024/UE7_Projet_DataBattle_IA-Pau/ia-pau-data-battle-mars-2024/backend/venv/lib/python3.11/site-packages (from torch>=1.11.0->sentence_transformers) (2.19.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/patrice/Documents/Etudes/CY-Tech/Ing2_Sem2_2023-2024/UE7_Projet_DataBattle_IA-Pau/ia-pau-data-battle-mars-2024/backend/venv/lib/python3.11/site-packages (from torch>=1.11.0->sentence_transformers) (12.1.105)\n",
      "Requirement already satisfied: triton==2.2.0 in /home/patrice/Documents/Etudes/CY-Tech/Ing2_Sem2_2023-2024/UE7_Projet_DataBattle_IA-Pau/ia-pau-data-battle-mars-2024/backend/venv/lib/python3.11/site-packages (from torch>=1.11.0->sentence_transformers) (2.2.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/patrice/Documents/Etudes/CY-Tech/Ing2_Sem2_2023-2024/UE7_Projet_DataBattle_IA-Pau/ia-pau-data-battle-mars-2024/backend/venv/lib/python3.11/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.11.0->sentence_transformers) (12.4.99)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/patrice/Documents/Etudes/CY-Tech/Ing2_Sem2_2023-2024/UE7_Projet_DataBattle_IA-Pau/ia-pau-data-battle-mars-2024/backend/venv/lib/python3.11/site-packages (from transformers<5.0.0,>=4.32.0->sentence_transformers) (2023.12.25)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /home/patrice/Documents/Etudes/CY-Tech/Ing2_Sem2_2023-2024/UE7_Projet_DataBattle_IA-Pau/ia-pau-data-battle-mars-2024/backend/venv/lib/python3.11/site-packages (from transformers<5.0.0,>=4.32.0->sentence_transformers) (0.15.2)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /home/patrice/Documents/Etudes/CY-Tech/Ing2_Sem2_2023-2024/UE7_Projet_DataBattle_IA-Pau/ia-pau-data-battle-mars-2024/backend/venv/lib/python3.11/site-packages (from transformers<5.0.0,>=4.32.0->sentence_transformers) (0.4.2)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /home/patrice/Documents/Etudes/CY-Tech/Ing2_Sem2_2023-2024/UE7_Projet_DataBattle_IA-Pau/ia-pau-data-battle-mars-2024/backend/venv/lib/python3.11/site-packages (from typer<0.10.0,>=0.3.0->spacy) (8.1.7)\n",
      "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /home/patrice/Documents/Etudes/CY-Tech/Ing2_Sem2_2023-2024/UE7_Projet_DataBattle_IA-Pau/ia-pau-data-battle-mars-2024/backend/venv/lib/python3.11/site-packages (from weasel<0.4.0,>=0.1.0->spacy) (0.16.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in /home/patrice/Documents/Etudes/CY-Tech/Ing2_Sem2_2023-2024/UE7_Projet_DataBattle_IA-Pau/ia-pau-data-battle-mars-2024/backend/venv/lib/python3.11/site-packages (from beautifulsoup4->bs4) (2.5)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/patrice/Documents/Etudes/CY-Tech/Ing2_Sem2_2023-2024/UE7_Projet_DataBattle_IA-Pau/ia-pau-data-battle-mars-2024/backend/venv/lib/python3.11/site-packages (from jinja2->spacy) (2.1.5)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /home/patrice/Documents/Etudes/CY-Tech/Ing2_Sem2_2023-2024/UE7_Projet_DataBattle_IA-Pau/ia-pau-data-battle-mars-2024/backend/venv/lib/python3.11/site-packages (from scikit-learn->sentence_transformers) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/patrice/Documents/Etudes/CY-Tech/Ing2_Sem2_2023-2024/UE7_Projet_DataBattle_IA-Pau/ia-pau-data-battle-mars-2024/backend/venv/lib/python3.11/site-packages (from scikit-learn->sentence_transformers) (3.4.0)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/patrice/Documents/Etudes/CY-Tech/Ing2_Sem2_2023-2024/UE7_Projet_DataBattle_IA-Pau/ia-pau-data-battle-mars-2024/backend/venv/lib/python3.11/site-packages (from sympy->torch>=1.11.0->sentence_transformers) (1.3.0)\n",
      "Collecting fr-core-news-sm==3.7.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/fr_core_news_sm-3.7.0/fr_core_news_sm-3.7.0-py3-none-any.whl (16.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.3/16.3 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.0 in /home/patrice/Documents/Etudes/CY-Tech/Ing2_Sem2_2023-2024/UE7_Projet_DataBattle_IA-Pau/ia-pau-data-battle-mars-2024/backend/venv/lib/python3.11/site-packages (from fr-core-news-sm==3.7.0) (3.7.4)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /home/patrice/Documents/Etudes/CY-Tech/Ing2_Sem2_2023-2024/UE7_Projet_DataBattle_IA-Pau/ia-pau-data-battle-mars-2024/backend/venv/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /home/patrice/Documents/Etudes/CY-Tech/Ing2_Sem2_2023-2024/UE7_Projet_DataBattle_IA-Pau/ia-pau-data-battle-mars-2024/backend/venv/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /home/patrice/Documents/Etudes/CY-Tech/Ing2_Sem2_2023-2024/UE7_Projet_DataBattle_IA-Pau/ia-pau-data-battle-mars-2024/backend/venv/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (1.0.10)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /home/patrice/Documents/Etudes/CY-Tech/Ing2_Sem2_2023-2024/UE7_Projet_DataBattle_IA-Pau/ia-pau-data-battle-mars-2024/backend/venv/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (2.0.8)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /home/patrice/Documents/Etudes/CY-Tech/Ing2_Sem2_2023-2024/UE7_Projet_DataBattle_IA-Pau/ia-pau-data-battle-mars-2024/backend/venv/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /home/patrice/Documents/Etudes/CY-Tech/Ing2_Sem2_2023-2024/UE7_Projet_DataBattle_IA-Pau/ia-pau-data-battle-mars-2024/backend/venv/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (8.2.3)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /home/patrice/Documents/Etudes/CY-Tech/Ing2_Sem2_2023-2024/UE7_Projet_DataBattle_IA-Pau/ia-pau-data-battle-mars-2024/backend/venv/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (1.1.2)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /home/patrice/Documents/Etudes/CY-Tech/Ing2_Sem2_2023-2024/UE7_Projet_DataBattle_IA-Pau/ia-pau-data-battle-mars-2024/backend/venv/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (2.4.8)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /home/patrice/Documents/Etudes/CY-Tech/Ing2_Sem2_2023-2024/UE7_Projet_DataBattle_IA-Pau/ia-pau-data-battle-mars-2024/backend/venv/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in /home/patrice/Documents/Etudes/CY-Tech/Ing2_Sem2_2023-2024/UE7_Projet_DataBattle_IA-Pau/ia-pau-data-battle-mars-2024/backend/venv/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (0.3.4)\n",
      "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /home/patrice/Documents/Etudes/CY-Tech/Ing2_Sem2_2023-2024/UE7_Projet_DataBattle_IA-Pau/ia-pau-data-battle-mars-2024/backend/venv/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (0.9.4)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /home/patrice/Documents/Etudes/CY-Tech/Ing2_Sem2_2023-2024/UE7_Projet_DataBattle_IA-Pau/ia-pau-data-battle-mars-2024/backend/venv/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (6.4.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /home/patrice/Documents/Etudes/CY-Tech/Ing2_Sem2_2023-2024/UE7_Projet_DataBattle_IA-Pau/ia-pau-data-battle-mars-2024/backend/venv/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (4.66.2)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /home/patrice/Documents/Etudes/CY-Tech/Ing2_Sem2_2023-2024/UE7_Projet_DataBattle_IA-Pau/ia-pau-data-battle-mars-2024/backend/venv/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (2.31.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /home/patrice/Documents/Etudes/CY-Tech/Ing2_Sem2_2023-2024/UE7_Projet_DataBattle_IA-Pau/ia-pau-data-battle-mars-2024/backend/venv/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (2.6.1)\n",
      "Requirement already satisfied: jinja2 in /home/patrice/Documents/Etudes/CY-Tech/Ing2_Sem2_2023-2024/UE7_Projet_DataBattle_IA-Pau/ia-pau-data-battle-mars-2024/backend/venv/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (3.1.3)\n",
      "Requirement already satisfied: setuptools in /home/patrice/Documents/Etudes/CY-Tech/Ing2_Sem2_2023-2024/UE7_Projet_DataBattle_IA-Pau/ia-pau-data-battle-mars-2024/backend/venv/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (65.5.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/patrice/Documents/Etudes/CY-Tech/Ing2_Sem2_2023-2024/UE7_Projet_DataBattle_IA-Pau/ia-pau-data-battle-mars-2024/backend/venv/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (24.0)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /home/patrice/Documents/Etudes/CY-Tech/Ing2_Sem2_2023-2024/UE7_Projet_DataBattle_IA-Pau/ia-pau-data-battle-mars-2024/backend/venv/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (3.3.0)\n",
      "Requirement already satisfied: numpy>=1.19.0 in /home/patrice/Documents/Etudes/CY-Tech/Ing2_Sem2_2023-2024/UE7_Projet_DataBattle_IA-Pau/ia-pau-data-battle-mars-2024/backend/venv/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (1.26.4)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /home/patrice/Documents/Etudes/CY-Tech/Ing2_Sem2_2023-2024/UE7_Projet_DataBattle_IA-Pau/ia-pau-data-battle-mars-2024/backend/venv/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.16.2 in /home/patrice/Documents/Etudes/CY-Tech/Ing2_Sem2_2023-2024/UE7_Projet_DataBattle_IA-Pau/ia-pau-data-battle-mars-2024/backend/venv/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (2.16.2)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /home/patrice/Documents/Etudes/CY-Tech/Ing2_Sem2_2023-2024/UE7_Projet_DataBattle_IA-Pau/ia-pau-data-battle-mars-2024/backend/venv/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (4.9.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/patrice/Documents/Etudes/CY-Tech/Ing2_Sem2_2023-2024/UE7_Projet_DataBattle_IA-Pau/ia-pau-data-battle-mars-2024/backend/venv/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/patrice/Documents/Etudes/CY-Tech/Ing2_Sem2_2023-2024/UE7_Projet_DataBattle_IA-Pau/ia-pau-data-battle-mars-2024/backend/venv/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/patrice/Documents/Etudes/CY-Tech/Ing2_Sem2_2023-2024/UE7_Projet_DataBattle_IA-Pau/ia-pau-data-battle-mars-2024/backend/venv/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/patrice/Documents/Etudes/CY-Tech/Ing2_Sem2_2023-2024/UE7_Projet_DataBattle_IA-Pau/ia-pau-data-battle-mars-2024/backend/venv/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (2024.2.2)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /home/patrice/Documents/Etudes/CY-Tech/Ing2_Sem2_2023-2024/UE7_Projet_DataBattle_IA-Pau/ia-pau-data-battle-mars-2024/backend/venv/lib/python3.11/site-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (0.7.11)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /home/patrice/Documents/Etudes/CY-Tech/Ing2_Sem2_2023-2024/UE7_Projet_DataBattle_IA-Pau/ia-pau-data-battle-mars-2024/backend/venv/lib/python3.11/site-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (0.1.4)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /home/patrice/Documents/Etudes/CY-Tech/Ing2_Sem2_2023-2024/UE7_Projet_DataBattle_IA-Pau/ia-pau-data-battle-mars-2024/backend/venv/lib/python3.11/site-packages (from typer<0.10.0,>=0.3.0->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (8.1.7)\n",
      "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /home/patrice/Documents/Etudes/CY-Tech/Ing2_Sem2_2023-2024/UE7_Projet_DataBattle_IA-Pau/ia-pau-data-battle-mars-2024/backend/venv/lib/python3.11/site-packages (from weasel<0.4.0,>=0.1.0->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (0.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/patrice/Documents/Etudes/CY-Tech/Ing2_Sem2_2023-2024/UE7_Projet_DataBattle_IA-Pau/ia-pau-data-battle-mars-2024/backend/venv/lib/python3.11/site-packages (from jinja2->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (2.1.5)\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('fr_core_news_sm')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/patrice/Documents/Etudes/CY-Tech/Ing2_Sem2_2023-2024/UE7_Projet_DataBattle_IA-Pau/ia-pau-data-battle-mars-2024/backend/venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas spacy bs4 sentence_transformers numpy\n",
    "!python -m spacy download fr_core_news_sm\n",
    "\n",
    "import pandas as pd\n",
    "import re\n",
    "import unicodedata\n",
    "import spacy\n",
    "from bs4 import BeautifulSoup\n",
    "from spacy.lang.fr.stop_words import STOP_WORDS\n",
    "import pickle\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from sentence_transformers.quantization import quantize_embeddings\n",
    "import numpy as np\n",
    "\n",
    "def load_and_merge_data(csv_file = '../data/solutions.csv'):\n",
    "    # Charger le fichier CSV en spécifiant le séparateur '|'\n",
    "    df = pd.read_csv(csv_file, sep='|', header=None)\n",
    "    # Renommer les colonnes\n",
    "    df.columns = ['id_solution', 'categorie', 'texte']\n",
    "    # Filtrer les lignes pour les catégories spécifiées\n",
    "    categories_specifiees = [1, 2, 5, 6]\n",
    "    df_filtre = df[df['categorie'].isin(categories_specifiees)]\n",
    "    # Pivoter les données pour obtenir les colonnes 'titre', 'definition', 'application' et 'bilan énergie'\n",
    "    df_pivot = df_filtre.pivot(index='id_solution', columns='categorie', values='texte').reset_index()\n",
    "    # Renommer les colonnes\n",
    "    df_pivot.columns = ['id_solution', 'titre', 'definition', 'application', 'bilan_energie']\n",
    "\n",
    "    # Ajouter un point à la fin des colonnes si nécessaire\n",
    "    colonnes = ['titre', 'definition', 'application', 'bilan_energie']\n",
    "    for col in colonnes:\n",
    "        df_pivot[col] = df_pivot[col].apply(lambda x: x.strip() + '.' if isinstance(x, str) and x.strip()[-1] != '.' else x.strip() if isinstance(x, str) else x)\n",
    "    \n",
    "    # Gérer les valeurs NaN lors de la fusion des colonnes\n",
    "    def combine_text(row):\n",
    "        text_parts = [row[col] for col in colonnes if pd.notnull(row[col])]\n",
    "        return ' '.join(text_parts)\n",
    "    \n",
    "    # Appliquer la fonction pour créer la nouvelle colonne 'text'\n",
    "    df_pivot['text'] = df_pivot.apply(combine_text, axis=1)\n",
    "\n",
    "    # Sélectionner uniquement les colonnes 'id_solution' et 'text'\n",
    "    df_final = df_pivot[['id_solution', 'text']]\n",
    "    \n",
    "    return df_final\n",
    "\n",
    "# Charger le modèle spaCy pour le français\n",
    "nlp = spacy.load(\"fr_core_news_sm\")\n",
    "\n",
    "def pre_processing(texte):\n",
    "    # Nettoyer HTML Tags\n",
    "    texte = BeautifulSoup(texte, 'html.parser').get_text()\n",
    "\n",
    "    # Remplacer \"&nbsp;.\" par rien\n",
    "    texte = re.sub(r'&nbsp;\\.', '', texte)\n",
    "\n",
    "    # Accents\n",
    "    texte = unicodedata.normalize('NFD', texte).encode('ascii', 'ignore').decode(\"utf-8\")\n",
    "\n",
    "    # Retirer les numéros\n",
    "    texte = re.sub(r'\\b\\d+\\b', '', texte)\n",
    "\n",
    "    # Tokenization, Lemmatization, Removing Stopwords, Lowercase\n",
    "    doc = nlp(texte)\n",
    "    phrases_propres = []\n",
    "    for phrase in doc.sents:\n",
    "        tokens = [token.lemma_.lower() for token in phrase if not token.is_stop and not token.is_punct and not token.is_space]\n",
    "        phrase_propre = ' '.join(tokens)\n",
    "        if phrase_propre:\n",
    "            phrases_propres.append(phrase_propre + \".\")  # Ajouter un point à la fin de la phrase propre\n",
    "\n",
    "    # Joining the cleaned sentences back into a single string\n",
    "    cleaned_text = ' '.join(phrases_propres)\n",
    "\n",
    "    return cleaned_text\n",
    "\n",
    "def calculate_average_embedding(text, quantize=False, precision=\"binary\"):\n",
    "    # Diviser le texte en phrases\n",
    "    sentences = [sentence.strip() for sentence in text.split('.') if sentence.strip()]\n",
    "    \n",
    "    # Calculer l'embedding de chaque phrase\n",
    "    if quantize :\n",
    "        sentence_embeddings = model.encode(sentences, precision=precision)\n",
    "    else :\n",
    "        sentence_embeddings = model.encode(sentences)\n",
    "    \n",
    "    # Prendre la moyenne des embeddings des phrases\n",
    "    if len(sentence_embeddings) > 0:\n",
    "        average_embedding = np.mean(sentence_embeddings, axis=0)\n",
    "    else:\n",
    "        average_embedding = np.zeros(model.get_sentence_embedding_dimension())\n",
    "    \n",
    "    return average_embedding\n",
    "\n",
    "def genere_embedding(data, output_file, quantize=False, precision=\"binary\"):\n",
    "\n",
    "    # Appliquer la fonction pour calculer l'embedding moyen à chaque texte\n",
    "    if quantize:\n",
    "        embeddings = data['clean_text'].apply(calculate_average_embedding, quantize=True)\n",
    "    else :\n",
    "        embeddings = data['clean_text'].apply(calculate_average_embedding)\n",
    "\n",
    "    \n",
    "    # Créer un nouveau DataFrame avec id_solution et les embeddings\n",
    "    new_data = {\n",
    "        'id_solution': data['id_solution'],\n",
    "        'text_embedding': embeddings\n",
    "    }\n",
    "    \n",
    "    # Créer un DataFrame à partir des nouvelles données\n",
    "    df_embeddings = pd.DataFrame(new_data)\n",
    "    \n",
    "    # Storer les embeddings dans un fichier\n",
    "    with open(output_file, \"wb\") as fOut:\n",
    "        pickle.dump(df_embeddings, fOut, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "    print(\"Les embeddings ont été storer avec succès.\")\n",
    "\n",
    "def find_solution(text_to_compare, embeddings_file, quantize=False, precision=\"binary\"):\n",
    "    # Calculer l'embedding moyen du texte à comparer\n",
    "    embedding_to_compare = calculate_average_embedding(text_to_compare, quantize, precision)\n",
    "    \n",
    "    # Charger les embeddings à partir du fichier\n",
    "    with open(embeddings_file, \"rb\") as fIn:\n",
    "        df_embeddings = pickle.load(fIn)\n",
    "    \n",
    "    # Convertir la liste de tableaux numpy en un seul tableau numpy\n",
    "    embeddings_array = np.stack(df_embeddings['text_embedding'].values)\n",
    "\n",
    "    # Calculer la similarité cosinus entre l'embedding à comparer et les embeddings dans df_embeddings\n",
    "    similarities = util.pytorch_cos_sim(embedding_to_compare.reshape(1, -1), embeddings_array)\n",
    "    \n",
    "    # Ajouter les similarités au DataFrame df_embeddings\n",
    "    df_embeddings['similarity'] = similarities.flatten()\n",
    "    \n",
    "    # Trier par similarité décroissante\n",
    "    df_sorted = df_embeddings.sort_values(by='similarity', ascending=False)\n",
    "    \n",
    "    # Récupérer les id_solution et les similarités\n",
    "    solution_info = df_sorted[['id_solution', 'similarity']].head(10)\n",
    "    \n",
    "    # Convertir en liste de tuples (id_solution, similarity)\n",
    "    solution_list = list(zip(solution_info['id_solution'], solution_info['similarity']))\n",
    "    \n",
    "    return solution_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Données utilisées pour la comparaison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Malheureusement nous n'avons pas reçu le domaine d'activité correspondant aux \n",
    "# requetes avec Kerdos.Et pour certaines requetes nous n'avons pas l'Id_solution non\n",
    "# plus, dans ce cas il est remplacé par -1.\n",
    "dataset_test_kerdos = [\n",
    "    [\"Id_solution\", \"Domaine_activite\", \"Description\"],\n",
    "    [724, \"\",\"C'est quoi la HP flottante ?\"],\n",
    "    [914, \"\", \"Je voudrais dimensionner un panneau solaire.\"],\n",
    "    [719, \"\", \"Quel gain pour un variateur de vitesse ?\"],\n",
    "    [-1, \"\", \"J'aimerais avoir une régulation optimisée de mon groupe froid.\"],\n",
    "    [-1, \"\", \"Comment faire pour réduire la consommation de mon compresseur d'air comprimé ?\"],\n",
    "    [-1, \"Pharmacie\", \"Quelles méthodes existent pour augmenter l'efficacité de la production des médicaments ?\"],\n",
    "    [-1, \"Pharmacy\", \"What methods exist to increase the efficiency of drug production?\"]\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fonction de test & model_pat modifié"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On adapte notre fonciton pour qu'elle prenne un nom de modèle en paramètre\n",
    "def model_PAT(secteur, description, model, model_name):\n",
    "    # Définition du nom du fichier d'embeddings\n",
    "    embeddings_file_path = model_name + \"_embeddings.pkl\"\n",
    "\n",
    "    # Vérifier si le fichier d'embeddings existe\n",
    "    if not os.path.exists(embeddings_file_path):\n",
    "        print(\"Le fichier d'embeddings n'existe pas. Génération des embeddings en cours...\")\n",
    "        # Affachage des données chargées\n",
    "        df_solutions = load_and_merge_data()\n",
    "        # Appliquons le traitement à la colonne text de notre df_solutions\n",
    "        df_solutions['clean_text'] = df_solutions['text'].apply(pre_processing)\n",
    "        # Générer les embeddings et les sauvegarder dans le fichier\n",
    "        genere_embedding(df_solutions, embeddings_file_path)\n",
    "        print(\"Les embeddings ont été générés et sauvegardés avec succès.\")\n",
    "\n",
    "    # On commence par concaténer notre secteur et notre description.\n",
    "    text = secteur + \". \" + description\n",
    "\n",
    "    # Ensuite on applique notre pré-processing\n",
    "    clean_text = pre_processing(text)\n",
    "\n",
    "    # Ensuite on cherche nos similarités \n",
    "    solutions = find_solution(clean_text, embeddings_file_path)\n",
    "\n",
    "    # On return une liste contenant uniquement le numéros des solutions\n",
    "    id_solutions = []\n",
    "    for solution in solutions :\n",
    "        id_solutions.append(solution[0])\n",
    "\n",
    "    return id_solutions\n",
    "\n",
    "def test(model, model_name) :\n",
    "    # On va tester sur notre dataset_test\n",
    "    for i in range(1, len(dataset_test_kerdos)):\n",
    "        print(\"--------------------------------------------\")\n",
    "        print(\"Solution attendue : \", dataset_test_kerdos[i][0])\n",
    "        print(model_PAT(dataset_test_kerdos[i][1], dataset_test_kerdos[i][2], model, model_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentence-Transformers : paraphrase-multilingual-MiniLM-L12-v2\n",
    "\n",
    "- Langage : Multilingue\n",
    "- Max Sequence Length : 128\n",
    "- Dimension de l'embedding : 384\n",
    "- Nombre de paramètres : Environ 71 millions\n",
    "- Temps génération embedding : 1 min 59\n",
    "- Embedding size : 1.7 MB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------\n",
      "Solution attendue :  724\n",
      "Le fichier d'embeddings n'existe pas. Génération des embeddings en cours...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_10223/3622992920.py:51: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  texte = BeautifulSoup(texte, 'html.parser').get_text()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Les embeddings ont été storer avec succès.\n",
      "Les embeddings ont été générés et sauvegardés avec succès.\n",
      "[722, 54, 1070, 724, 386, 1144, 222, 335, 1533, 329]\n",
      "--------------------------------------------\n",
      "Solution attendue :  914\n",
      "[270, 1486, 1453, 1452, 1456, 1454, 1455, 1457, 1446, 1447]\n",
      "--------------------------------------------\n",
      "Solution attendue :  719\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/patrice/Documents/Etudes/CY-Tech/Ing2_Sem2_2023-2024/UE7_Projet_DataBattle_IA-Pau/ia-pau-data-battle-mars-2024/backend/venv/lib/python3.11/site-packages/sentence_transformers/util.py:41: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:275.)\n",
      "  b = torch.tensor(b)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1533, 1445, 1144, 1140, 1649, 1595, 1596, 346, 54, 444]\n",
      "--------------------------------------------\n",
      "Solution attendue :  -1\n",
      "[1049, 149, 44, 803, 148, 5, 723, 3, 259, 483]\n",
      "--------------------------------------------\n",
      "Solution attendue :  -1\n",
      "[152, 154, 1056, 157, 145, 171, 502, 1001, 165, 153]\n"
     ]
    }
   ],
   "source": [
    "# Charger le modèle\n",
    "model = SentenceTransformer(\"paraphrase-multilingual-MiniLM-L12-v2\")\n",
    "test(model, \"paraphrase-multilingual-MiniLM-L12-v2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentence-Transformers : paraphrase-multilingual-mpnet-base-v2\n",
    "\n",
    "- distiluse-base-multilingual-cased-v1: Multilingual knowledge distilled version of multilingual Universal Sentence Encoder. Supports 15 languages: Arabic, Chinese, Dutch, English, French, German, Italian, Korean, Polish, Portuguese, Russian, Spanish, Turkish.\n",
    "\n",
    "- distiluse-base-multilingual-cased-v2: Multilingual knowledge distilled version of multilingual Universal Sentence Encoder. This version supports 50+ languages, but performs a bit weaker than the v1 model.\n",
    "\n",
    "- paraphrase-multilingual-MiniLM-L12-v2 - Multilingual version of paraphrase-MiniLM-L12-v2, trained on parallel data for 50+ languages.\n",
    "\n",
    "- paraphrase-multilingual-mpnet-base-v2 - Multilingual version of paraphrase-mpnet-base-v2, trained on parallel data for 50+ languages.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------\n",
      "Solution attendue :  724\n",
      "Le fichier d'embeddings n'existe pas. Génération des embeddings en cours...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_17800/3622992920.py:51: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  texte = BeautifulSoup(texte, 'html.parser').get_text()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Les embeddings ont été storer avec succès.\n",
      "Les embeddings ont été générés et sauvegardés avec succès.\n",
      "[724, 102, 722, 823, 1103, 1600, 1613, 1454, 1456, 1455]\n",
      "--------------------------------------------\n",
      "Solution attendue :  914\n",
      "[818, 270, 1486, 858, 914, 1635, 368, 1554, 1631, 1636]\n",
      "--------------------------------------------\n",
      "Solution attendue :  719\n",
      "[1649, 1595, 1445, 1596, 1144, 719, 1533, 1592, 1140, 1653]\n",
      "--------------------------------------------\n",
      "Solution attendue :  -1\n",
      "[1049, 483, 259, 723, 1693, 149, 4, 918, 1130, 9]\n",
      "--------------------------------------------\n",
      "Solution attendue :  -1\n",
      "[1056, 1001, 165, 152, 1058, 209, 153, 145, 154, 1051]\n",
      "--------------------------------------------\n",
      "Solution attendue :  -1\n",
      "[1054, 1141, 1011, 1469, 495, 275, 930, 65, 743, 482]\n",
      "--------------------------------------------\n",
      "Solution attendue :  -1\n",
      "[1054, 930, 495, 482, 503, 1141, 1690, 1011, 876, 1007]\n"
     ]
    }
   ],
   "source": [
    "# Charger le modèle\n",
    "model = SentenceTransformer(\"paraphrase-multilingual-mpnet-base-v2\")\n",
    "test(model, \"paraphrase-multilingual-mpnet-base-v2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentence-Transformers : La BSE\n",
    "\n",
    "- Langage : Multilingue\n",
    "- Max Sequence Length : 128\n",
    "- Dimension de l'embedding : 768\n",
    "- Nombre de paramètres : Environ 176 millions\n",
    "- Temps génération embedding : 9 min 47\n",
    "- Embedding size : 3.4 MB\n",
    "\n",
    "Link : https://www.kaggle.com/models/google/labse/frameworks/tensorFlow2/variations/labse/versions/1?tfhub-redirect=true\n",
    "\n",
    "Note : Il semble **hyper pertinent pour lui poser une question en Anglais et qu'il réponde en Français** par exemple. Dans l'idée on pourrait prendre des requetes dans n'importe quelle langue et renvoyer correctement les solutions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------\n",
      "Solution attendue :  724\n",
      "[724, 1604, 1602, 835, 1461, 1597, 1605, 310, 1070, 328]\n",
      "--------------------------------------------\n",
      "Solution attendue :  914\n",
      "[270, 818, 1455, 1457, 1453, 1558, 1454, 1456, 1632, 914]\n",
      "--------------------------------------------\n",
      "Solution attendue :  719\n",
      "[1533, 1589, 210, 1596, 139, 1595, 79, 1653, 1592, 63]\n",
      "--------------------------------------------\n",
      "Solution attendue :  -1\n",
      "[1049, 1693, 918, 866, 44, 483, 19, 1128, 9, 149]\n",
      "--------------------------------------------\n",
      "Solution attendue :  -1\n",
      "[154, 1056, 332, 157, 778, 1051, 151, 29, 153, 152]\n",
      "--------------------------------------------\n",
      "Solution attendue :  -1\n",
      "[1054, 1080, 1141, 340, 395, 3, 1007, 995, 738, 1622]\n",
      "--------------------------------------------\n",
      "Solution attendue :  -1\n",
      "[1054, 1080, 1141, 340, 395, 1007, 738, 995, 310, 3]\n"
     ]
    }
   ],
   "source": [
    "# Charger le modèle\n",
    "model = SentenceTransformer(\"sentence-transformers/LaBSE\")\n",
    "test(model, \"LaBSE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentence-Transformers : Camembert Base\n",
    "\n",
    "- Langage : Français\n",
    "- Max Sequence Length : 128\n",
    "- Dimension de l'embedding : 768\n",
    "- Nombre de paramètres : Environ 110 millions\n",
    "\n",
    "- Temps génération embedding : 5 min 54\n",
    "- Embedding size : 3.4 MB\n",
    "\n",
    "On dev :\n",
    "- Prearson correlation : 86.73\n",
    "- Spearman correlation : 86.54\n",
    "\n",
    "Link : https://huggingface.co/dangvantuan/sentence-camembert-base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------\n",
      "Solution attendue :  724\n",
      "Le fichier d'embeddings n'existe pas. Génération des embeddings en cours...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_10223/3622992920.py:51: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  texte = BeautifulSoup(texte, 'html.parser').get_text()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Les embeddings ont été storer avec succès.\n",
      "Les embeddings ont été générés et sauvegardés avec succès.\n",
      "[1602, 1604, 835, 724, 834, 1609, 1610, 1603, 388, 1458]\n",
      "--------------------------------------------\n",
      "Solution attendue :  914\n",
      "[1454, 1456, 1455, 1457, 270, 818, 73, 1452, 179, 1632]\n",
      "--------------------------------------------\n",
      "Solution attendue :  719\n",
      "[1592, 1653, 1445, 1533, 1589, 79, 719, 1596, 1014, 1595]\n",
      "--------------------------------------------\n",
      "Solution attendue :  -1\n",
      "[19, 1049, 922, 918, 44, 1037, 1048, 969, 3, 17]\n",
      "--------------------------------------------\n",
      "Solution attendue :  -1\n",
      "[154, 720, 153, 36, 502, 778, 1056, 146, 390, 1051]\n"
     ]
    }
   ],
   "source": [
    "# Charger le modèle\n",
    "model = SentenceTransformer(\"dangvantuan/sentence-camembert-base\")\n",
    "test(model, \"Camembert-base\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentence-Transformers : Camembert Large\n",
    "\n",
    "- Langage : Français\n",
    "- Max Sequence Length : 128\n",
    "- Dimension de l'embedding : 768\n",
    "- Nombre de paramètres : Environ 340 millions\n",
    "- Temps génération embedding : 14m \n",
    "- Embedding size : 4.5 MB\n",
    "\n",
    "On dev :\n",
    "- Prearson correlation : 88.2\n",
    "- Spearman correlation : 88.02\n",
    "\n",
    "Link : https://huggingface.co/dangvantuan/sentence-camembert-base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No sentence-transformers model found with name dangvantuan/sentence-camembert-large. Creating a new one with MEAN pooling.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------\n",
      "Solution attendue :  724\n",
      "[1604, 835, 724, 1602, 1603, 1608, 1606, 723, 1610, 1609]\n",
      "--------------------------------------------\n",
      "Solution attendue :  914\n",
      "[270, 1454, 1456, 1632, 1457, 1455, 1448, 1450, 914, 1452]\n",
      "--------------------------------------------\n",
      "Solution attendue :  719\n",
      "[1596, 1595, 719, 1533, 1445, 63, 79, 1589, 1592, 1653]\n",
      "--------------------------------------------\n",
      "Solution attendue :  -1\n",
      "[1049, 758, 1114, 19, 1048, 867, 294, 3, 34, 922]\n",
      "--------------------------------------------\n",
      "Solution attendue :  -1\n",
      "[154, 153, 1056, 778, 152, 332, 165, 170, 150, 1092]\n",
      "--------------------------------------------\n",
      "Solution attendue :  -1\n",
      "[495, 3, 1561, 482, 494, 974, 1497, 236, 1578, 1010]\n",
      "--------------------------------------------\n",
      "Solution attendue :  -1\n",
      "[1561, 1010, 974, 495, 1559, 943, 427, 970, 482, 1054]\n"
     ]
    }
   ],
   "source": [
    "# Charger le modèle\n",
    "model = SentenceTransformer(\"dangvantuan/sentence-camembert-large\")\n",
    "test(model, \"Camembert-large\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparaison modèles (sur laptop)\n",
    "\n",
    "| Nom modèle | Langage | Temps génération embedding | Taille embedding | Temps requette | Accuracy\n",
    "|------------|---------|----------------------------|------------------|----------------|---------|\n",
    "| paraphrase-multilingual-MiniLM-L12-v2 | Multi | 2min| 1.7MB| 0.1s| |\n",
    "| paraphrase-multilingual-mpnet-base-v2 | Multi | 8min30| 3.4MB| 0.1s| |\n",
    "| sentence-transformers/LaBSE | Multi | 10min| 3.4MB| 0.1s| |\n",
    "| dangvantuan/sentence-camembert-base | Fr | 6min|3.4MB| 0.1s| | \n",
    "| dangvantuan/sentence-camembert-large| Fr | 14min|4.5MB| 0.1s| |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine tunning\n",
    "\n",
    "Notre dataset n'étant pas très grand et étant ammené à évolué avec le temps, nous avons décidé de ne pas fine tuner notre modèle dessus, afin de ne pas le spécialiser sur le peu de données que nous possédons en prenant le risque de perdre en généralisation sur le moyen/long terme."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NOTES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notre étude va se dérouler en plusieurs parties. \n",
    "\n",
    "1. Mise en place d'un modèle de base :\n",
    "\n",
    "    **pre_traitement()**\n",
    "\n",
    "    Entrée : nos csv\n",
    "    \n",
    "    Sortie : Une matrice contenant les données que nous pensons utile pour ce modèle après avoir enlevé les stop_words, la ponctuation et les majuscules.\n",
    "\n",
    "    \n",
    "    **Choix d'un modèle de base**\n",
    "\n",
    "    **genere_embedding()**\n",
    "\n",
    "    Entrée : la sortie de pre_traitement()\n",
    "    \n",
    "    Sortie : stock dans un fichier les embeddings correspondant à nos solutions.\n",
    "\n",
    "    **find_solution()**\n",
    "\n",
    "    Entrée : secteur, description\n",
    "\n",
    "    Sortie : Une liste des meilleures solutions classés dans l'orde. On peut imaginer mettre une limite par exemple distance cos > 0.65\n",
    "\n",
    "    **Tester conso dans gaia**\n",
    "\n",
    "2. Creation d'un Test set \n",
    "\n",
    "    **Creation du test_set**\n",
    "\n",
    "    On génère des description et domaine d'activité en fonction des infos de solution avec GPT4. On génère différent niveau de précision par solution.\n",
    "\n",
    "    **test_model()**\n",
    "\n",
    "    Entrée : find_solution() de notre modèle et test_set.\n",
    "\n",
    "    Sortie : On renvoie une accuracy. On considère que si le modèle prédit la bonne solution dans son top 3 sol, c'est validé.\n",
    "\n",
    "3. Test de différents modèles. L'idée est d'avoir un tableau avec la conso, l'accuracy et le model pour expliquer pourquoi on a pris celui-ci plutôt qu'un autre.\n",
    "\n",
    "    **Faire un tableau de tests**\n",
    "    \n",
    "    Tester différents modèles et type de modèles, Word2Vec, FastText, SentenceTransformers (plusieurs).\n",
    "    \n",
    "    **Test Fine tuning**\n",
    "    \n",
    "    Fine tunner le meilleur pour voir le résultat.\n",
    "\n",
    "    **Si temps, on peut même tenter d'entrainer un modèle sur notre test set avec notre méthode**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Génération test set \n",
    "\n",
    "En utilisant GPT4, prendre des lots de 20 solutions, générer doaine d'activité et description de ce qu'un utilisateur pourrait demander. En générer 3 ou 4 par solutions avec différents niveau de précision. Le faire pour une centaine de solutions.\n",
    "\n",
    "On aurrait donc X = [description, domaine_activitée], y = [num_solution ].\n",
    "\n",
    "Pour tester notre modèle on peut tenter de lui faire prédire les meilleures solutions en fonction de la description et du domaine_activitée. Si la solution correspondante est dans le top 3 des solutions prédites, on considère que c'est une réussite."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Modèles à tester\n",
    "\n",
    "\n",
    "TF-IDF (c'est long et peu performant mais méthode sans embedding. On peut en parler dans Questionnaire et dire qu'on ne l'a pas implémenté car peu pertinent suivant les études qu'on a lu.)\n",
    "\n",
    "FastText (on a un token par mot et on fait la moyenne pour avoir le texte)\n",
    "\n",
    "Sentence transformers (un token par phrase et on fait la moyenne pour avoir le texte)\n",
    "\n",
    "Doc2Vec (document lvl)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
